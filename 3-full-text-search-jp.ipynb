{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160462cc",
   "metadata": {},
   "source": [
    "# 日本語全文検索の実装\n",
    "> この章は、`full-text-search-jp.ipynb` を元に作成しています。\n",
    "\n",
    "## 概要\n",
    "日本語の全部検索を実装する場合は、以下のような事項について考慮が必要です。\n",
    "\n",
    "- 多様な文字種: 日本語検索では、ひらがな、カタカナ、漢字、英数字(半角・全角)、特殊記号(①や㌢など)、顔文字など、様々な文字種を取り扱う。\n",
    "- 表記ゆれへの対応。表記が異なっていても同じ語句として扱う必要がある。\n",
    "  - 文字種、全角半角、大文字小文字の違いで発生する揺らぎ(あいふぉん、アイフォン、アイフォーン、iphone、i-Phone、iPhone、ｉｐｈｏｎｅ など)\n",
    "  - 末尾の長音記号(ー)の有無による揺らぎ(コンピューターとコンピュータ)\n",
    "  - 長音記号とカタカナによる揺らぎ(サラダボールとサラダボウルは同じ単語として処理する必要があるが、バレエとバレーは異なる単語として処理する必要がある)\n",
    "  - 漢字の踊り字による揺らぎ(明明白白、明々白々)\n",
    "- 複合語の処理: 複数の語句が結合した複合語は、一つの単語として処理する要件が存在する(山桜、東京タワー、エアバスA300、ホームページ、瀬戸内しまなみ海道 など)\n",
    "- 類義語の処理類似するキーワードで検索できるようにする必要がある。(正確/的確/明確/確実/確か など)\n",
    "\n",
    "本ラボでは、OpenSearch で日本語検索実装上の課題にどのように対応するかを解説していきます。\n",
    "\n",
    "### ラボの構成\n",
    "本ラボでは、ノートブック環境（EC2 へ Remote Develop 接続した VSCode）および Amazon OpenSearch Serverless を使用します。\n",
    "\n",
    "<img src=\"./img/architecture.png\" width=\"512\"> \n",
    "\n",
    "### 使用するデータセット\n",
    "本ラボでは、[JGLUE][jglue] 内の FAQ データセットである [JSQuAD][jsquad] を使用します。\n",
    "\n",
    "[jglue]: https://github.com/yahoojapan/JGLUE\n",
    "[jsquad]: https://github.com/yahoojapan/JGLUE/tree/main/datasets/jsquad-v1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c47c9a",
   "metadata": {},
   "source": [
    "## 事前作業\n",
    "\n",
    "### パッケージインストール\n",
    "実行する前に、タブの右上のカーネルの選択を確認してください。\n",
    "\n",
    "> opensearch と awswrangler のバージョンの依存関係のため、opensearch-py 側を止めています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f57a078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m62 packages\u001b[0m \u001b[2min 161ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m4.0.14                           \u001b[0m     \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipywidgets\u001b[0m\u001b[2m==8.1.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyterlab-widgets\u001b[0m\u001b[2m==3.0.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwidgetsnbextension\u001b[0m\u001b[2m==4.0.14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add \"opensearch-py<3\" requests-aws4auth awswrangler[opensearch] ipywidgets python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b8918",
   "metadata": {},
   "source": [
    "### 環境変数\n",
    "`.env`ファイルに、以下の環境変数を設定します。\n",
    "\n",
    "- AOSS_SEARCH_HOST=`AOSS の検索コレクションのエンドポイントのホスト名`\n",
    "- AOSS_VECTOR_HOST=`AOSS のベクトル検索コレクションのエンドポイントのホスト名`\n",
    "- AOSS_ROLE_ARN=`AOSS から Bedrock へアクセスするために作成したロールのARN`\n",
    "\n",
    "設定できたら、以下のコマンドを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1dcc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv -o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc7826e",
   "metadata": {},
   "source": [
    "### インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e53795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "from ipywidgets import interact\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6b86f",
   "metadata": {},
   "source": [
    "### 共通変数のセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e90d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_region = boto3.Session().region_name\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d85dbb",
   "metadata": {},
   "source": [
    "### OpenSearch Serverless への接続確認\n",
    "OpenSearch Server のセキュリティ設定により、API リクエストが許可されているかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531e5706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' OPEN jsquad-kuromoji efKH-ZgB_vf32jNhdAKd   67139 0 44.6mb 44.6mb\\n OPEN movie-users     cpNv-JgBcgEDf7NLRkzh       1 0  3.6kb  3.6kb\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoss_host = os.getenv(\"AOSS_SEARCH_HOST\")\n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "service_code = \"aoss\"\n",
    "auth = AWSV4SignerAuth(credentials=credentials, region=default_region, service=service_code)\n",
    "opensearch_client = OpenSearch(\n",
    "    hosts=[{\"host\": aoss_host, \"port\": 443}],\n",
    "    http_compress=True, \n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")\n",
    "opensearch_client.cat.indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6320497",
   "metadata": {},
   "source": [
    "## 日本語検索ウォークスルー\n",
    "### OpenSearch におけるテキスト処理の全体像\n",
    "\n",
    "全文検索の対象となるデータは、以下の流れで処理され、転置インデックスに登録されます。\n",
    "\n",
    "<img src=\"./img/analyzer.png\" width=\"1024\">\n",
    "\n",
    "以降のセクションでは、各フェーズで登場するコンポーネントの解説と、具体的なコンポーネントの動作を見ていきます。\n",
    "\n",
    "### Tokenizer\n",
    "Tokenizer は入力されたテキストを自身のロジックに基づいて分割するコンポーネントです。日本語検索では形態素解析を用いる手法、もしくは n-Gram という N 文字ずつテキストを区切る手法が一般的に用いられます。各手法について実際の挙動を見ていきましょう。\n",
    "\n",
    "#### N-Gram\n",
    "N-Gram はテキストから N 文字ずつ取り出してトークン化する手法です。 一文字ずつ取り出すことを uni-gram、二文字ずつ切り取ることを bi-gram、三文字ずつ切り取ることを tri-gram などと呼びます。\n",
    "\n",
    "ここでは、N-Gram tokenizer で、以下の文字列を 2 文字ずつトークン化した結果を見ていきます。トークンにホワイトスペースや記号が含まれないように、**token_chars** パラメーターで制御を行っています。\n",
    "\n",
    "\"大阪府の関西国際空港(KIX)から東京都の羽田空港(HND)までのフライト時間はおよそ 70 分です\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c28158cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>大阪</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>阪府</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>府の</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>の関</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>関西</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>word</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>西国</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>国際</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>word</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>際空</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>word</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>空港</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KI</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>word</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IX</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>word</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>から</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>word</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ら東</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>word</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>東京</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>word</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>京都</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>word</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>都の</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>word</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>の羽</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>word</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>羽田</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>word</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>田空</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>word</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>空港</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>word</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HN</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>word</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ND</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>word</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>まで</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>word</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>での</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>word</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>のフ</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>word</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>フラ</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>word</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ライ</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>word</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>イト</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>word</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ト時</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>word</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>時間</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>word</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>間は</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>word</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>はお</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>word</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>およ</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>word</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>よそ</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>word</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>word</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>分で</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>word</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>です</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  start_offset  end_offset  type  position\n",
       "0     大阪             0           2  word         0\n",
       "1     阪府             1           3  word         1\n",
       "2     府の             2           4  word         2\n",
       "3     の関             3           5  word         3\n",
       "4     関西             4           6  word         4\n",
       "5     西国             5           7  word         5\n",
       "6     国際             6           8  word         6\n",
       "7     際空             7           9  word         7\n",
       "8     空港             8          10  word         8\n",
       "9     KI            11          13  word         9\n",
       "10    IX            12          14  word        10\n",
       "11    から            15          17  word        11\n",
       "12    ら東            16          18  word        12\n",
       "13    東京            17          19  word        13\n",
       "14    京都            18          20  word        14\n",
       "15    都の            19          21  word        15\n",
       "16    の羽            20          22  word        16\n",
       "17    羽田            21          23  word        17\n",
       "18    田空            22          24  word        18\n",
       "19    空港            23          25  word        19\n",
       "20    HN            26          28  word        20\n",
       "21    ND            27          29  word        21\n",
       "22    まで            30          32  word        22\n",
       "23    での            31          33  word        23\n",
       "24    のフ            32          34  word        24\n",
       "25    フラ            33          35  word        25\n",
       "26    ライ            34          36  word        26\n",
       "27    イト            35          37  word        27\n",
       "28    ト時            36          38  word        28\n",
       "29    時間            37          39  word        29\n",
       "30    間は            38          40  word        30\n",
       "31    はお            39          41  word        31\n",
       "32    およ            40          42  word        32\n",
       "33    よそ            41          43  word        33\n",
       "34    70            44          46  word        34\n",
       "35    分で            47          49  word        35\n",
       "36    です            48          50  word        36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"大阪府の関西国際空港(KIX)から東京都の羽田空港(HND)までのフライト時間はおよそ 70 分です。\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"ngram\",\n",
    "    \"min_gram\": 2,\n",
    "    \"max_gram\": 2,\n",
    "    \"token_chars\": [\"letter\", \"digit\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_bigram = pd.json_normalize(response[\"tokens\"])\n",
    "df_bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d0345",
   "metadata": {},
   "source": [
    "上記の例では、文章を 1 文字ずつずらしながら、2 文字のトークンが抽出されたことがわかります。N-Gram は N 文字ずつトークンを抽出することから、未知語に対するヒット率の向上が期待できます。\n",
    "\n",
    "一方、検索ノイズの増加については考慮が必要です。抽出されたトークンには **\"京都\"** も含まれているため、`京都`で検索を行った際に無関係の本文章がヒットしてしまいます。\n",
    "\n",
    "検索ノイズを削減するテクニックとしては以下のようなものが考えられます。\n",
    "\n",
    "- 複数の N-Gram (bi-gram と tri-gram など)インデックスを併用し、ユーザーが入力した検索キーワードの長さに応じて、アプリケーション側で処理を分岐させる\n",
    "- 形態素解析と組み合わせる\n",
    "- トークンフィルターを適用し、\"です\" や \"ます\" などの不要な語句(ストップワード)で構成されるトークンを除去する\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<b>N-gram の最小文字数と最大文字数に 2 以上の差がある場合の設定</b>\n",
    "\n",
    "ngram tokenizer の min_gram および max_gram に 2 以上の差がある場合は、インデックスに [index.max_ngram_diff][index-settings] の設定を追加する必要があります。追加されていない場合、以下のようなエラーが発生します。\n",
    "</div>\n",
    "\n",
    "[index-settings]: https://opensearch.org/docs/latest/install-and-configure/configuring-opensearch/index-settings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8070112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RequestError(400, 'illegal_argument_exception', 'The difference between max_gram and min_gram in NGram Tokenizer must be less than or equal to: [1] but was [2]. This limit can be set by changing the [index.max_ngram_diff] index level setting.')\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"大阪府の関西国際空港(KIX)から東京都の羽田空港(HND)までのフライト時間はおよそ 70 分です。\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"ngram\",\n",
    "    \"min_gram\": 1,\n",
    "    \"max_gram\": 3,\n",
    "  }\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = opensearch_client.indices.analyze(\n",
    "      body=payload\n",
    "    )\n",
    "    df_bigram = pd.json_normalize(response[\"tokens\"])\n",
    "    df_bigram\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d10165",
   "metadata": {},
   "source": [
    "#### 形態素解析\n",
    "形態素解析を用いることで、単語の品詞情報が格納された辞書や文法に基づくトークン分割を行えます。\n",
    "\n",
    "例えば、吾輩は猫である。 という文章を形態素解析エンジンで処理すると、吾輩 / は / 猫 / で / ある / 。 と自然に分割されたトークンが取得できます。\n",
    "\n",
    "OpenSearch では、Sudachi もしくは Kuromoji を利用可能ですが、OpenSearch Serverless では、Sudachi は利用できません。以降のセクションでは、Kuromoji の動作を解説していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3bf80",
   "metadata": {},
   "source": [
    "##### Kuromoji\n",
    "Kuromoji は Java で実装されたオープンソースの日本語形態素解析ツールです。[atilika][atilika] により開発、Apache Software Foundation に寄贈されており、OpenSearch のベースである Apache Lucene に組み込まれています。Amazon OpenSearch Service および Amazon OpenSearch Serverless では、デフォルトで Kuromoji が利用可能です。\n",
    "\n",
    "OSS 版の OpenSearch でも、標準の[日本語プラグイン][additional-plugins]として登録されているため、`opensearch-plugin install analysis-kuromoji` コマンドで導入が可能です。\n",
    "\n",
    "kuromoji_tokenizer は、以下 3 つの分割モードをサポートしています。\n",
    "\n",
    "- normal: デフォルトのモード。最も長い分割単位でトークンを出力。複合トークンの分割は行わない。\n",
    "- search: 検索に特化したモード。複合トークンの分割も合わせて行う。\n",
    "- extended: search の動作に加えて、未知語をユニグラム(1 文字トークン)として出力する\n",
    "\n",
    "各モードごとの実行結果を見ていきましょう。\n",
    "\n",
    "[atilika]: https://www.atilika.org/\n",
    "[additional-plugins]: https://opensearch.org/docs/latest/install-and-configure/additional-plugins/index/\n",
    "\n",
    "**normal モード**\n",
    "\n",
    "カッコなどの記号や句読点がトークンに含まれていないのは、kuromoji tokenizer の **discard_punctuation** オプションがデフォルトで `true` になっているためです。記号や句読点をトークンとして含める場合は同設定を `false` にセットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b57dde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>大阪</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>府</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>の</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>関西国際空港</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KIX</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>word</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>から</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>東京</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>word</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>都</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>word</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>の</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>word</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>羽田空港</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>word</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HND</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>word</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>まで</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>word</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>の</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>word</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>フライト</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>word</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>時間</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>word</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>は</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>word</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>およそ</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>word</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>word</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>分</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>word</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>です</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  start_offset  end_offset  type  position\n",
       "0       大阪             0           2  word         0\n",
       "1        府             2           3  word         1\n",
       "2        の             3           4  word         2\n",
       "3   関西国際空港             4          10  word         3\n",
       "4      KIX            11          14  word         4\n",
       "5       から            15          17  word         5\n",
       "6       東京            17          19  word         6\n",
       "7        都            19          20  word         7\n",
       "8        の            20          21  word         8\n",
       "9     羽田空港            21          25  word         9\n",
       "10     HND            26          29  word        10\n",
       "11      まで            30          32  word        11\n",
       "12       の            32          33  word        12\n",
       "13    フライト            33          37  word        13\n",
       "14      時間            37          39  word        14\n",
       "15       は            39          40  word        15\n",
       "16     およそ            40          43  word        16\n",
       "17      70            44          46  word        17\n",
       "18       分            47          48  word        18\n",
       "19      です            48          50  word        19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"大阪府の関西国際空港(KIX)から東京都の羽田空港(HND)までのフライト時間はおよそ 70 分です。\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"normal\",\n",
    "    \"discard_punctuation\": True #デフォルト\n",
    "  }\n",
    "}\n",
    "\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji_normal = pd.json_normalize(response[\"tokens\"])\n",
    "df_kuromoji_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d093177",
   "metadata": {},
   "source": [
    "**search モード**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fc7380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "      <th>positionLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>大阪</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>府</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>の</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>関西</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>関西国際空港</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>国際</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>word</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>空港</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KIX</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>word</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>から</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>word</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>東京</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>word</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>都</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>word</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>の</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>word</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>羽田</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>word</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>羽田空港</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>word</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>空港</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>word</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HND</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>word</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>まで</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>word</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>の</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>word</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>フライト</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>word</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>時間</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>word</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>は</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>word</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>およそ</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>word</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>word</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>分</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>word</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>です</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  start_offset  end_offset  type  position  positionLength\n",
       "0       大阪             0           2  word         0             NaN\n",
       "1        府             2           3  word         1             NaN\n",
       "2        の             3           4  word         2             NaN\n",
       "3       関西             4           6  word         3             NaN\n",
       "4   関西国際空港             4          10  word         3             3.0\n",
       "5       国際             6           8  word         4             NaN\n",
       "6       空港             8          10  word         5             NaN\n",
       "7      KIX            11          14  word         6             NaN\n",
       "8       から            15          17  word         7             NaN\n",
       "9       東京            17          19  word         8             NaN\n",
       "10       都            19          20  word         9             NaN\n",
       "11       の            20          21  word        10             NaN\n",
       "12      羽田            21          23  word        11             NaN\n",
       "13    羽田空港            21          25  word        11             2.0\n",
       "14      空港            23          25  word        12             NaN\n",
       "15     HND            26          29  word        13             NaN\n",
       "16      まで            30          32  word        14             NaN\n",
       "17       の            32          33  word        15             NaN\n",
       "18    フライト            33          37  word        16             NaN\n",
       "19      時間            37          39  word        17             NaN\n",
       "20       は            39          40  word        18             NaN\n",
       "21     およそ            40          43  word        19             NaN\n",
       "22      70            44          46  word        20             NaN\n",
       "23       分            47          48  word        21             NaN\n",
       "24      です            48          50  word        22             NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"大阪府の関西国際空港(KIX)から東京都の羽田空港(HND)までのフライト時間はおよそ 70 分です\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\"\n",
    "  }\n",
    "}\n",
    "\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji_search = pd.json_normalize(response[\"tokens\"])\n",
    "df_kuromoji_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00d382",
   "metadata": {},
   "source": [
    "**extended モード**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f13716c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "      <th>positionLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>大阪</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>府</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>の</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>関西</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>関西国際空港</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>国際</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>word</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>空港</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>word</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>word</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>word</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>から</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>word</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>東京</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>word</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>都</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>word</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>の</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>word</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>羽田</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>word</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>羽田空港</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>word</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>空港</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>word</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>H</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>word</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>N</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>word</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>D</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>word</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>まで</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>word</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>の</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>word</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>フライト</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>word</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>時間</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>word</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>は</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>word</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>およそ</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>word</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>word</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>word</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>分</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>word</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>です</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  start_offset  end_offset  type  position  positionLength\n",
       "0       大阪             0           2  word         0             NaN\n",
       "1        府             2           3  word         1             NaN\n",
       "2        の             3           4  word         2             NaN\n",
       "3       関西             4           6  word         3             NaN\n",
       "4   関西国際空港             4          10  word         3             3.0\n",
       "5       国際             6           8  word         4             NaN\n",
       "6       空港             8          10  word         5             NaN\n",
       "7        K            11          12  word         6             NaN\n",
       "8        I            12          13  word         7             NaN\n",
       "9        X            13          14  word         8             NaN\n",
       "10      から            15          17  word         9             NaN\n",
       "11      東京            17          19  word        10             NaN\n",
       "12       都            19          20  word        11             NaN\n",
       "13       の            20          21  word        12             NaN\n",
       "14      羽田            21          23  word        13             NaN\n",
       "15    羽田空港            21          25  word        13             2.0\n",
       "16      空港            23          25  word        14             NaN\n",
       "17       H            26          27  word        15             NaN\n",
       "18       N            27          28  word        16             NaN\n",
       "19       D            28          29  word        17             NaN\n",
       "20      まで            30          32  word        18             NaN\n",
       "21       の            32          33  word        19             NaN\n",
       "22    フライト            33          37  word        20             NaN\n",
       "23      時間            37          39  word        21             NaN\n",
       "24       は            39          40  word        22             NaN\n",
       "25     およそ            40          43  word        23             NaN\n",
       "26       7            44          45  word        24             NaN\n",
       "27       0            45          46  word        25             NaN\n",
       "28       分            47          48  word        26             NaN\n",
       "29      です            48          50  word        27             NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"大阪府の関西国際空港(KIX)から東京都の羽田空港(HND)までのフライト時間はおよそ 70 分です\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"extended\"\n",
    "  }\n",
    "}\n",
    "\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji_extended = pd.json_normalize(response[\"tokens\"])\n",
    "df_kuromoji_extended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5b1d8",
   "metadata": {},
   "source": [
    "**normal/search/extended モードの比較**\n",
    "3 つのモードを比較します。normal -> search -> extended の順にトークンが増加する様子が分かります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b17c11f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_offset</th>\n",
       "      <th>token_kuromoji_extended</th>\n",
       "      <th>token_kuromoji_search</th>\n",
       "      <th>token_kuromoji_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>大阪</td>\n",
       "      <td>大阪</td>\n",
       "      <td>大阪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>府</td>\n",
       "      <td>府</td>\n",
       "      <td>府</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>関西</td>\n",
       "      <td>関西</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>関西</td>\n",
       "      <td>関西国際空港</td>\n",
       "      <td>関西国際空港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>関西国際空港</td>\n",
       "      <td>関西</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>関西国際空港</td>\n",
       "      <td>関西国際空港</td>\n",
       "      <td>関西国際空港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>国際</td>\n",
       "      <td>国際</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>空港</td>\n",
       "      <td>空港</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>K</td>\n",
       "      <td>KIX</td>\n",
       "      <td>KIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>I</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>から</td>\n",
       "      <td>から</td>\n",
       "      <td>から</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>東京</td>\n",
       "      <td>東京</td>\n",
       "      <td>東京</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>都</td>\n",
       "      <td>都</td>\n",
       "      <td>都</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>羽田</td>\n",
       "      <td>羽田</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21</td>\n",
       "      <td>羽田</td>\n",
       "      <td>羽田空港</td>\n",
       "      <td>羽田空港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>羽田空港</td>\n",
       "      <td>羽田</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>羽田空港</td>\n",
       "      <td>羽田空港</td>\n",
       "      <td>羽田空港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23</td>\n",
       "      <td>空港</td>\n",
       "      <td>空港</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26</td>\n",
       "      <td>H</td>\n",
       "      <td>HND</td>\n",
       "      <td>HND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28</td>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>まで</td>\n",
       "      <td>まで</td>\n",
       "      <td>まで</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>フライト</td>\n",
       "      <td>フライト</td>\n",
       "      <td>フライト</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>37</td>\n",
       "      <td>時間</td>\n",
       "      <td>時間</td>\n",
       "      <td>時間</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>39</td>\n",
       "      <td>は</td>\n",
       "      <td>は</td>\n",
       "      <td>は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>40</td>\n",
       "      <td>およそ</td>\n",
       "      <td>およそ</td>\n",
       "      <td>およそ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>47</td>\n",
       "      <td>分</td>\n",
       "      <td>分</td>\n",
       "      <td>分</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>48</td>\n",
       "      <td>です</td>\n",
       "      <td>です</td>\n",
       "      <td>です</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_offset token_kuromoji_extended token_kuromoji_search  \\\n",
       "0              0                      大阪                    大阪   \n",
       "1              2                       府                     府   \n",
       "2              3                       の                     の   \n",
       "3              4                      関西                    関西   \n",
       "4              4                      関西                関西国際空港   \n",
       "5              4                  関西国際空港                    関西   \n",
       "6              4                  関西国際空港                関西国際空港   \n",
       "7              6                      国際                    国際   \n",
       "8              8                      空港                    空港   \n",
       "9             11                       K                   KIX   \n",
       "10            12                       I                         \n",
       "11            13                       X                         \n",
       "12            15                      から                    から   \n",
       "13            17                      東京                    東京   \n",
       "14            19                       都                     都   \n",
       "15            20                       の                     の   \n",
       "16            21                      羽田                    羽田   \n",
       "17            21                      羽田                  羽田空港   \n",
       "18            21                    羽田空港                    羽田   \n",
       "19            21                    羽田空港                  羽田空港   \n",
       "20            23                      空港                    空港   \n",
       "21            26                       H                   HND   \n",
       "22            27                       N                         \n",
       "23            28                       D                         \n",
       "24            30                      まで                    まで   \n",
       "25            32                       の                     の   \n",
       "26            33                    フライト                  フライト   \n",
       "27            37                      時間                    時間   \n",
       "28            39                       は                     は   \n",
       "29            40                     およそ                   およそ   \n",
       "30            44                       7                    70   \n",
       "31            45                       0                         \n",
       "32            47                       分                     分   \n",
       "33            48                      です                    です   \n",
       "\n",
       "   token_kuromoji_normal  \n",
       "0                     大阪  \n",
       "1                      府  \n",
       "2                      の  \n",
       "3                         \n",
       "4                 関西国際空港  \n",
       "5                         \n",
       "6                 関西国際空港  \n",
       "7                         \n",
       "8                         \n",
       "9                    KIX  \n",
       "10                        \n",
       "11                        \n",
       "12                    から  \n",
       "13                    東京  \n",
       "14                     都  \n",
       "15                     の  \n",
       "16                        \n",
       "17                  羽田空港  \n",
       "18                        \n",
       "19                  羽田空港  \n",
       "20                        \n",
       "21                   HND  \n",
       "22                        \n",
       "23                        \n",
       "24                    まで  \n",
       "25                     の  \n",
       "26                  フライト  \n",
       "27                    時間  \n",
       "28                     は  \n",
       "29                   およそ  \n",
       "30                    70  \n",
       "31                        \n",
       "32                     分  \n",
       "33                    です  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kuromoji_search_and_normal = pd.merge(df_kuromoji_search, df_kuromoji_normal, on=[\"start_offset\", \"end_offset\"], how=\"left\", suffixes=[\"_kuromoji_search\",\"_kuromoji_normal\"]).drop([\"type_kuromoji_search\",\"type_kuromoji_normal\",\"positionLength\",\"position_kuromoji_search\", \"position_kuromoji_normal\"],axis=1).reindex([\"start_offset\", \"end_offset\", \"token_kuromoji_search\", \"token_kuromoji_normal\"],axis=1).fillna(\"\")\n",
    "df_kuromoji_extended_and_normal = pd.merge(df_kuromoji_extended, df_kuromoji_normal, on=[\"start_offset\", \"end_offset\"], how=\"left\", suffixes=[\"_kuromoji_extended\",\"_kuromoji_normal\"]).drop([\"type_kuromoji_extended\",\"type_kuromoji_normal\",\"positionLength\",\"position_kuromoji_extended\",\"position_kuromoji_normal\"],axis=1).reindex([\"start_offset\", \"end_offset\", \"token_kuromoji_extended\", \"token_kuromoji_normal\"],axis=1)\n",
    "df_kuromoji = pd.merge(df_kuromoji_extended_and_normal, df_kuromoji_search_and_normal, on=[\"start_offset\"], how=\"left\").drop([\"token_kuromoji_normal_x\"],axis=1).rename(columns={\"token_kuromoji_normal_y\": \"token_kuromoji_normal\"}).reindex([\"start_offset\", \"token_kuromoji_extended\", \"token_kuromoji_search\", \"token_kuromoji_normal\"],axis=1).fillna(\"\")\n",
    "df_kuromoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f1820",
   "metadata": {},
   "source": [
    "なお、search もしくは extended モードで、分割前の複合語を破棄する場合は、**discard_compound_token** に `true` をセットします。以下は search モードにおける **discard_compound_token** パラメーターによる結果の違いです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eae9290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>token_without_discard_compound_token</th>\n",
       "      <th>token_with_discard_compound_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>大阪</td>\n",
       "      <td>大阪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>府</td>\n",
       "      <td>府</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>関西</td>\n",
       "      <td>関西</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>関西国際空港</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>国際</td>\n",
       "      <td>国際</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>空港</td>\n",
       "      <td>空港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>KIX</td>\n",
       "      <td>KIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>から</td>\n",
       "      <td>から</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>東京</td>\n",
       "      <td>東京</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>都</td>\n",
       "      <td>都</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>羽田</td>\n",
       "      <td>羽田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>羽田空港</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>空港</td>\n",
       "      <td>空港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>HND</td>\n",
       "      <td>HND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>まで</td>\n",
       "      <td>まで</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>フライト</td>\n",
       "      <td>フライト</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>時間</td>\n",
       "      <td>時間</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>は</td>\n",
       "      <td>は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>およそ</td>\n",
       "      <td>およそ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>分</td>\n",
       "      <td>分</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>です</td>\n",
       "      <td>です</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_offset  end_offset token_without_discard_compound_token  \\\n",
       "0              0           2                                   大阪   \n",
       "1              2           3                                    府   \n",
       "2              3           4                                    の   \n",
       "3              4           6                                   関西   \n",
       "4              4          10                               関西国際空港   \n",
       "5              6           8                                   国際   \n",
       "6              8          10                                   空港   \n",
       "7             11          14                                  KIX   \n",
       "8             15          17                                   から   \n",
       "9             17          19                                   東京   \n",
       "10            19          20                                    都   \n",
       "11            20          21                                    の   \n",
       "12            21          23                                   羽田   \n",
       "13            21          25                                 羽田空港   \n",
       "14            23          25                                   空港   \n",
       "15            26          29                                  HND   \n",
       "16            30          32                                   まで   \n",
       "17            32          33                                    の   \n",
       "18            33          37                                 フライト   \n",
       "19            37          39                                   時間   \n",
       "20            39          40                                    は   \n",
       "21            40          43                                  およそ   \n",
       "22            44          46                                   70   \n",
       "23            47          48                                    分   \n",
       "24            48          50                                   です   \n",
       "\n",
       "   token_with_discard_compound_token  \n",
       "0                                 大阪  \n",
       "1                                  府  \n",
       "2                                  の  \n",
       "3                                 関西  \n",
       "4                                     \n",
       "5                                 国際  \n",
       "6                                 空港  \n",
       "7                                KIX  \n",
       "8                                 から  \n",
       "9                                 東京  \n",
       "10                                 都  \n",
       "11                                 の  \n",
       "12                                羽田  \n",
       "13                                    \n",
       "14                                空港  \n",
       "15                               HND  \n",
       "16                                まで  \n",
       "17                                 の  \n",
       "18                              フライト  \n",
       "19                                時間  \n",
       "20                                 は  \n",
       "21                               およそ  \n",
       "22                                70  \n",
       "23                                 分  \n",
       "24                                です  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"大阪府の関西国際空港(KIX)から東京都の羽田空港(HND)までのフライト時間はおよそ 70 分です\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\",\n",
    "    \"discard_compound_token\": True\n",
    "  }\n",
    "}\n",
    "\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji_search_discard_compound_token = pd.json_normalize(response[\"tokens\"])\n",
    "df_kuromoji_search_results = pd.merge(df_kuromoji_search, df_kuromoji_search_discard_compound_token, on=[\"start_offset\", \"end_offset\"], how=\"left\", suffixes=[\"_without_discard_compound_token\",\"_with_discard_compound_token\"]).drop([\"type_without_discard_compound_token\",\"type_with_discard_compound_token\",\"positionLength\",\"position_without_discard_compound_token\", \"position_with_discard_compound_token\"],axis=1).reindex([\"start_offset\", \"end_offset\", \"token_without_discard_compound_token\", \"token_with_discard_compound_token\"],axis=1).fillna(\"\")\n",
    "df_kuromoji_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d0ab34",
   "metadata": {},
   "source": [
    "### Character Filter\n",
    "Tokenizer に渡す前段での正規化を担当するコンポーネントです。不要な文字の除去や半角・全角を揃えるなどの正規化処理を行うことで、表記ゆれによる検索精度の低下を防ぎます。\n",
    "\n",
    "Character Filter には踊り字の置き換えといった、トークン分割自体の精度向上に寄与するものもあります。\n",
    "\n",
    "#### ICU normalization character filter\n",
    "\n",
    "ICU normalization character filter は、文字列の正規化処理を行うフィルターです。以下のような表記ゆれを補正可能です。\n",
    "\n",
    "| 変換内容 | 変換例(前) |変換例(後)|\n",
    "| ---- | ---- | ---- |\n",
    "| 大文字 -> 小文字 | OpenSearch | opensearch |\n",
    "| 全角英数字・記号 -> 半角英数字・記号 | oｐeｎ＿sｅaｒcｈ | open_search |\n",
    "| 半角カナ -> 全角カナ | ｵｰﾌﾟﾝｿｰｽ\t| オープンソース |\n",
    "| 数字記号 -> 半角数字 | ① | 1 |\n",
    "| 単位記号 -> 全角カナ | ㍍ | メートル |\n",
    "\n",
    "以下の例では、様々な種類の文字が混在する文字列の正規化を行っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9cca85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>token</th>\n",
       "      <th>token_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>OｐeｎsｅaｒCｈ</td>\n",
       "      <td>opensearch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>は</td>\n",
       "      <td>は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>①⓪⓪</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>パーセント</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td>オープン</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>ｵｰﾌﾟンｿｰｽ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>ソース</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>検索</td>\n",
       "      <td>検索</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>分析</td>\n",
       "      <td>分析</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>スイート</td>\n",
       "      <td>スイート</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>です</td>\n",
       "      <td>です</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_offset  end_offset       token token_normalized\n",
       "0              0          10  OｐeｎsｅaｒCｈ       opensearch\n",
       "1             10          11           は                は\n",
       "2             11          14         ①⓪⓪              100\n",
       "3             14          15                        パーセント\n",
       "4             15          20                         オープン\n",
       "5             15          23    ｵｰﾌﾟンｿｰｽ                 \n",
       "6             20          23                          ソース\n",
       "7             23          24           の                の\n",
       "8             24          26          検索               検索\n",
       "9             27          29          分析               分析\n",
       "10            29          33        スイート             スイート\n",
       "11            33          35          です               です"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"OｐeｎsｅaｒCｈは①⓪⓪㌫ｵｰﾌﾟンｿｰｽの検索／分析スイートです\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\"\n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_sudachi = pd.json_normalize(response[\"tokens\"])\n",
    "\n",
    "payload = {\n",
    "  \"text\": \"OｐeｎsｅaｒCｈは①⓪⓪㌫ｵｰﾌﾟンｿｰｽの検索／分析スイートです\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\"\n",
    "  },\n",
    "  \"char_filter\": [\"icu_normalizer\"]\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_sudachi_normalized = pd.json_normalize(response[\"tokens\"])\n",
    "\n",
    "pd.merge(df_sudachi, df_sudachi_normalized, on=[\"start_offset\",\"end_offset\"], how=\"outer\").rename(columns={\"token_x\": \"token\", \"token_y\": \"token_normalized\"}).reindex([\"start_offset\", \"end_offset\", \"token\", \"token_normalized\"],axis=1).fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab596251",
   "metadata": {},
   "source": [
    "#### kuromoji_iteration_mark character filter\n",
    "kuromoji_iteration_mark は、踊り字(々, ゝ, ヽ)を直前の文字で置き換える機能を提供します。<br>\n",
    "踊り字を変換せずにそのままトークン分割を行った場合、以下のような問題が発生します\n",
    "\n",
    "- トークン分割時に踊り字だけがインデクシングされてしまう\n",
    "- 踊り字を含むキーワードで検索を行った際に、踊り字を含むすべてのキーワードがヒットしてしまう\n",
    "- 文字列の分割箇所がおかしくなる\n",
    "\n",
    "例えば、**こゝろ** や **つゝむ** をそのまま Kuromoji Tokenizer で処理すると、ゝ が一つのトークンとして抽出されます。このままの状態でインデックスにデータが格納された場合、`こゝろ` で検索を行うと、**つゝむ** もヒットしてしまいます。\n",
    "\n",
    "また、学問のすゝめ については、学問/の/すゝ/め と不自然な位置で区切られてしまいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aea1cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>こ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ゝ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ろ</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  start_offset  end_offset  type  position\n",
       "0     こ             0           1  word         0\n",
       "1     ゝ             1           2  word         1\n",
       "2     ろ             2           3  word         2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"こゝろ\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\"\n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2b83754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>つ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ゝ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>む</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  start_offset  end_offset  type  position\n",
       "0     つ             0           1  word         0\n",
       "1     ゝ             1           2  word         1\n",
       "2     む             2           3  word         2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"つゝむ\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\"\n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30686a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>学問</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>の</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>すゝ</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>め</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  start_offset  end_offset  type  position\n",
       "0    学問             0           2  word         0\n",
       "1     の             2           3  word         1\n",
       "2    すゝ             3           5  word         2\n",
       "3     め             5           6  word         3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"学問のすゝめ\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\"\n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e514ae",
   "metadata": {},
   "source": [
    "`kuromoji_iteration_mark` を利用することで、踊り字がひとつ前の文字に置き換えられ、トークンが正しく抽出されるようになります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66641262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>学問</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>の</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>すすめ</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  start_offset  end_offset  type  position\n",
       "0    学問             0           2  word         0\n",
       "1     の             2           3  word         1\n",
       "2   すすめ             3           6  word         2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"学問のすゝめ\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\"\n",
    "  },\n",
    "  \"char_filter\": [\"kuromoji_iteration_mark\"]\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a5ecb",
   "metadata": {},
   "source": [
    "### Token Filter\n",
    "Token Filter は Tokenizer によって分割・抽出されたトークンに対する処理を行います。検索ノイズの増加に影響するストップワードや特定の品詞の除去、ステミングや表記ゆれの補正など、検索精度を向上するうえで欠かせない処理が提供されています。<br>\n",
    "以降、主要な Token Filter について解説していきます。\n",
    "\n",
    "なお、Token Filter の中には、品詞分類などを手掛かりとして処理を行うものが存在します。こうした処理は、同じプラグイン(Kuromoji、Sudachi)でトークナイズされていることが前提となるため、Kuromoji で生成されたトークンを Sudachi のトークンフィルタで処理できない場合があります。\n",
    "\n",
    "#### 原形への置き換え\n",
    "変化形を原形に置き換えてインデックスへの格納・検索を行うことで、食べる と 食べた といった形の違いによる検索ヒット率の低下を防ぎます。\n",
    "Kuromoji でトークン分割を行った場合は **kuromoji_baseform** Token Filter を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b5265ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>token</th>\n",
       "      <th>token_baseform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>寿司</td>\n",
       "      <td>寿司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>を</td>\n",
       "      <td>を</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>食べ</td>\n",
       "      <td>食べる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>た</td>\n",
       "      <td>た</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>美味しかっ</td>\n",
       "      <td>美味しい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>た</td>\n",
       "      <td>た</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>な</td>\n",
       "      <td>な</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_offset  end_offset  token token_baseform\n",
       "0             0           2     寿司             寿司\n",
       "1             2           3      を              を\n",
       "2             3           5     食べ            食べる\n",
       "3             5           6      た              た\n",
       "4             7          12  美味しかっ           美味しい\n",
       "5            12          13      た              た\n",
       "6            13          14      な              な"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"text\": \"寿司を食べた。美味しかったな\"\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji = pd.json_normalize(response[\"tokens\"])\n",
    "\n",
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\"kuromoji_baseform\"],\n",
    "  \"text\": \"寿司を食べた。美味しかったな\"\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji_baseform = pd.json_normalize(response[\"tokens\"])\n",
    "\n",
    "pd.merge(df_kuromoji_baseform, df_kuromoji, on=[\"start_offset\",\"end_offset\"], how=\"outer\").rename(columns={\"token_x\": \"token_baseform\", \"token_y\": \"token\"}).reindex([\"start_offset\", \"end_offset\", \"token\", \"token_baseform\"],axis=1).fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02ccd7",
   "metadata": {},
   "source": [
    "#### 品詞分類によるトークン除去\n",
    "トークナイザーにより抽出されたトークンには品詞の情報が付与されています。品詞分類を元に、助詞や接続詞などの検索ノイズになりうるトークンを削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78e7ed4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>token_baseform</th>\n",
       "      <th>token_baseform_part_of_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>寿司</td>\n",
       "      <td>寿司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>を</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>食べる</td>\n",
       "      <td>食べる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>た</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>美味しい</td>\n",
       "      <td>美味しい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>た</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>な</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_offset  end_offset token_baseform token_baseform_part_of_speech\n",
       "0             0           2             寿司                            寿司\n",
       "1             2           3              を                              \n",
       "2             3           5            食べる                           食べる\n",
       "3             5           6              た                              \n",
       "4             7          12           美味しい                          美味しい\n",
       "5            12          13              た                              \n",
       "6            13          14              な                              "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\"kuromoji_baseform\"],\n",
    "  \"text\": \"寿司を食べた。美味しかったな\"\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji_baseform = pd.json_normalize(response[\"tokens\"])\n",
    "\n",
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    \"kuromoji_baseform\",\n",
    "    {\n",
    "        \"type\": \"kuromoji_part_of_speech\",\n",
    "        \"stoptags\": [\n",
    "          \"助詞-格助詞-一般\",\n",
    "          \"助動詞\",\n",
    "          \"助詞-終助詞\"\n",
    "        ]\n",
    "    }\n",
    "  ],\n",
    "  \"text\": \"寿司を食べた。美味しかったな\"\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji_baseform_part_of_speech = pd.json_normalize(response[\"tokens\"])\n",
    "\n",
    "pd.merge(df_kuromoji_baseform, df_kuromoji_baseform_part_of_speech, on=[\"start_offset\",\"end_offset\"], how=\"outer\").rename(columns={\"token_x\": \"token_baseform\", \"token_y\": \"token_baseform_part_of_speech\"}).reindex([\"start_offset\", \"end_offset\", \"token_baseform\", \"token_baseform_part_of_speech\"],axis=1).fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5650d62",
   "metadata": {},
   "source": [
    "#### ストップワードの除去\n",
    "日本語における \"てにをは\" など、検索において重要ではない語句をストップワードと呼びます。<br>\n",
    "ストップワードがインデックスに格納されると検索性が低下するため、一般的にはインデックスに格納されないよう除去します。品詞単位の除去に似ていますが、ストップワードの除去は品詞の分類による判断ではなく、ストップワードリストを元に判断します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46b69b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>token</th>\n",
       "      <th>token_ja_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>寿司</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>を</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>食べる</td>\n",
       "      <td>食べる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>た</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>美味しい</td>\n",
       "      <td>美味しい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>た</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>な</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_offset  end_offset token token_ja_stop\n",
       "0             0           2    寿司              \n",
       "1             2           3     を              \n",
       "2             3           5   食べる           食べる\n",
       "3             5           6     た              \n",
       "4             7          12  美味しい          美味しい\n",
       "5            12          13     た              \n",
       "6            13          14     な              "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    \"kuromoji_baseform\"\n",
    "  ],\n",
    "  \"text\": \"寿司を食べた。美味しかったな\"\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji = pd.json_normalize(response[\"tokens\"])\n",
    "\n",
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    \"kuromoji_baseform\",\n",
    "    {\n",
    "      \"type\": \"ja_stop\",\n",
    "      \"stopwords\": [\"_japanese_\",\"寿司\"]\n",
    "    }\n",
    "  ],\n",
    "  \"text\": \"寿司を食べた。美味しかったな\"\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "df_kuromoji_sudachi_ja_stop = pd.json_normalize(response[\"tokens\"])\n",
    "\n",
    "pd.merge(df_kuromoji, df_kuromoji_sudachi_ja_stop, on=[\"start_offset\",\"end_offset\"], how=\"outer\").rename(columns={\"token_x\": \"token\", \"token_y\": \"token_ja_stop\"}).reindex([\"start_offset\", \"end_offset\", \"token\", \"token_ja_stop\"],axis=1).fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bebad63",
   "metadata": {},
   "source": [
    "#### 類義語\n",
    "OpenSearch では類義語を同じ語句として取り扱うことで検索精度を向上させます。\n",
    "\n",
    "例えば、\"パイン\"、\"パイナップル\" など、同じものを指していても、表記が異なれば異なるキーワードとして扱われます。以下は実際の動作例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0d60aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>パイン</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>パイナップル</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  start_offset  end_offset  type  position\n",
       "0     パイン             0           3  word         0\n",
       "1  パイナップル             4          10  word       101"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"text\": [\"パイン\", \"パイナップル\"]\n",
    "} \n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dddbe5",
   "metadata": {},
   "source": [
    "シノニムを設定することで、インデクシング時および検索時にテキストの類義語を展開することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bd20311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>パイナップル</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>SYNONYM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ゼリー</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>パイナップル</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>word</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>アイス</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>word</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  start_offset  end_offset     type  position\n",
       "0  パイナップル             0           3  SYNONYM         0\n",
       "1     ゼリー             3           6     word         1\n",
       "2  パイナップル             7          13     word       102\n",
       "3     アイス            13          16     word       103"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    {\n",
    "      \"type\": \"synonym\",\n",
    "      \"lenient\": False,\n",
    "      \"synonyms\": [ \"パイン=> パイナップル\" ]\n",
    "    }\n",
    "  ],\n",
    "  \"text\": [\"パインゼリー\", \"パイナップルアイス\"]\n",
    "} \n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1660d36",
   "metadata": {},
   "source": [
    "_analyze API の実行結果で type が SYNONYM となっているものは、シノニムの定義により展開・出力されたトークンであることを表します。上記の例でパインがパイナップルに変化したのは、シノニム設定時に、矢印 (=>) で展開方向を抑制しているためです。 矢印 (=>) で展開方向を抑制したことで、パイン は パイナップルに変換されてからインデックスに格納されます\n",
    "\n",
    "一方、矢印を記載せずにカンマで区切った場合、シノニムは相互展開されます。以下は展開例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab48d2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>パイン</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>パイナップル</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>SYNONYM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ゼリー</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>パイナップル</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>word</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>パイン</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>SYNONYM</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>アイス</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>word</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  start_offset  end_offset     type  position\n",
       "0     パイン             0           3     word         0\n",
       "1  パイナップル             0           3  SYNONYM         0\n",
       "2     ゼリー             3           6     word         1\n",
       "3  パイナップル             7          13     word       102\n",
       "4     パイン             7          13  SYNONYM       102\n",
       "5     アイス            13          16     word       103"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    {\n",
    "      \"type\": \"synonym\",\n",
    "      \"lenient\": False,\n",
    "      \"synonyms\": [ \"パイン,パイナップル\" ]\n",
    "    }\n",
    "  ],\n",
    "  \"text\": [\"パインゼリー\", \"パイナップルアイス\"]\n",
    "} \n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d50f9e",
   "metadata": {},
   "source": [
    "#### カナおよびローマ字読みへの変換\n",
    "トークンをカナ表記、ローマ字表記に変換することで検索ワードの揺らぎを補正することが可能です。\n",
    "\n",
    "Sudachi と Kuromoji それぞれで固有の readingform filter を使用する必要があります。kuromoji_tokenizer に対しては kuromoji_readingform を使用します。\n",
    "\n",
    "use_romaji オプションを true にするとローマ字に、false にするとカタカナに変換されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1101c7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ika</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ika</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ika</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>word</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  start_offset  end_offset  type  position\n",
       "0   ika             0           2  word         0\n",
       "1   ika             3           5  word       101\n",
       "2   ika             6           8  word       202"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    {\n",
    "      \"type\": \"kuromoji_readingform\",\n",
    "      \"use_romaji\": True\n",
    "    },\n",
    "  ],\n",
    "  \"text\": [\"いか\", \"烏賊\", \"イカ\"]\n",
    "} \n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f4eb74",
   "metadata": {},
   "source": [
    "変換の精度は辞書に依存します。例えば、\"紅まどんな(べにまどんな)\" は Kuromoji のデフォルトシステム辞書に登録されていないため、トークン分割された上に \"べに\" ではなく \"あか\" と読まれてしまいます。\n",
    "カスタム辞書に読み仮名を含めて登録することで対処可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a793e2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>アカ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>マ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ドンナ</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  start_offset  end_offset  type  position\n",
       "0    アカ             0           1  word         0\n",
       "1     マ             1           2  word         1\n",
       "2   ドンナ             2           5  word         2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    {\n",
    "      \"type\": \"kuromoji_readingform\",\n",
    "      \"use_romaji\": False\n",
    "    },\n",
    "  ],\n",
    "  \"text\": [\"紅まどんな\"]\n",
    "} \n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc070c",
   "metadata": {},
   "source": [
    "もう一つの注意点として、同音異字も同じ文字に変換されます。これは検索ノイズの増加につながる可能性があります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0364343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>カンジョウ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>カンジョウ</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>カンジョウ</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>word</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  start_offset  end_offset  type  position\n",
       "0  カンジョウ             0           2  word         0\n",
       "1  カンジョウ             3           5  word       101\n",
       "2  カンジョウ             6           8  word       202"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    {\n",
    "      \"type\": \"kuromoji_readingform\",\n",
    "      \"use_romaji\": False\n",
    "    },\n",
    "  ],\n",
    "  \"text\": [\"感情\", \"勘定\", \"環状\"]\n",
    "} \n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d7d00e",
   "metadata": {},
   "source": [
    "#### その他の正規化機能\n",
    "その他、各形態素解析器固有の機能について解説していきます。\n",
    "\n",
    "##### 長音記号のステミング (Kuromoji)\n",
    "Kuromoji kuromoji_stemmer と呼ばれるトークン末尾の長音記号(ー)を削除する機能を提供します。minimum_length オプションで、長音記号を削除するトークンの最小文字数を指定することが可能です。\n",
    "\n",
    "* minimum_length オプションで指定した文字長未満のトークンは末尾の長音記号削除は行われません。デフォルト値は 4 です。この数値は以前の JISZ8301 にて、3音以上の言葉については語尾に長音符号を付けない、2音以下の言葉については語尾に調音符号を付与するというものに由来していると考えられます。2024 年現在の JISZ8301 ではこの基準は削除されています。\n",
    "* 本 Token Filter は全角カナのみが対象となるため、半角カナや全角かなに適用するためには、icu_normalizer による半角カナ->全角カナの置き換えや、kuromoji_readingform による全角かな->全角カナへの置き換えが必要です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0fc237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>コピー</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>サーバ</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>word</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  start_offset  end_offset  type  position\n",
       "0   コピー             0           3  word         0\n",
       "1   サーバ             4           8  word       101"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    {\n",
    "      \"type\": \"kuromoji_stemmer\",\n",
    "      \"minimum_length\": 4 #default\n",
    "    }\n",
    "  ],\n",
    "  \"text\": [\"コピー\", \"サーバー\"]\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9847136",
   "metadata": {},
   "source": [
    "詳細については、[内閣告示・内閣訓令 「外来語の表記　留意事項その2(細則的な事項)」][gairai]や、JTCA の[「TC 関連ガイドライン」][tc_guide]をご覧ください。\n",
    "\n",
    "[gairai]: https://www.bunka.go.jp/kokugo_nihongo/sisaku/joho/joho/kijun/naikaku/gairai/honbun06.html\n",
    "[tc_guide]: https://jtca.org/useful/tc_guide/\n",
    "\n",
    "語末の長音記号の有無による表記ゆれを解消できる本 Token Filter ですが、長音記号を削除することで元々の単語の意味が変わってしまう副作用には注意が必要です。\n",
    "\n",
    "例えば、コーラー(caller) 末尾の長音記号を削除した場合、生成されるトークンは コーラ(Cola) となり語句の意味自体が変わってしまいます。\n",
    "\n",
    "このような問題を抑制するために minimum_length 設定があります。デフォルト値の 4 を使用した場合、以下のようなケースを防止可能です。\n",
    "\n",
    "- エコー(echo) -> エコ(eco)\n",
    "- エラー(error) -> エラ(era)\n",
    "- カバー(cover) -> カバ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed49f6",
   "metadata": {},
   "source": [
    "##### アラビア数字への置き換え (Kuromoji)\n",
    "Kuromoji は kuromoji_number と呼ばれる、漢数字をアラビア数字に置換する機能を提供します。置換対象の漢数字は Lucene の [JapaneseNumberFilter.java](https://github.com/apache/lucene/blob/main/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseNumberFilter.java) より確認可能です。\n",
    "\n",
    "対応している単位は垓(10 の 20 乗) までです。\n",
    "\n",
    "アラビア数字への置き換えは、Tokenizer により分割されたトークンが漢数字で構成された文字列のみが対象となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3199cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "      <th>positionLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000000000000000001001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2510</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>word</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>円</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>word</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>です</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>word</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>千載</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>word</td>\n",
       "      <td>204</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>千載一遇</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>word</td>\n",
       "      <td>204</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>一</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>word</td>\n",
       "      <td>205</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>遇</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>word</td>\n",
       "      <td>206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      token  start_offset  end_offset  type  position  \\\n",
       "0  100000000000000000001001             0           4  word         0   \n",
       "1                      2510             5          11  word       101   \n",
       "2                         円            11          12  word       102   \n",
       "3                        です            12          14  word       103   \n",
       "4                        千載            15          17  word       204   \n",
       "5                      千載一遇            15          19  word       204   \n",
       "6                         一            17          18  word       205   \n",
       "7                         遇            18          19  word       206   \n",
       "\n",
       "   positionLength  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "5             3.0  \n",
       "6             NaN  \n",
       "7             NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "  \"filter\": [\n",
    "    {\n",
    "      \"type\": \"kuromoji_number\"\n",
    "    }\n",
    "  ],\n",
    "  \"text\": [\"千垓千一\",  \"二千,五百十円です\", \"千載一遇\"]\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af129d8",
   "metadata": {},
   "source": [
    "## 日本語検索の実行\n",
    "サンプルインデックスにデータをロードし、いくつかの日本語検索を実行していきます。\n",
    "\n",
    "### サンプルデータの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "086a0f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.9 ms, sys: 1.01 ms, total: 41.9 ms\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset_dir = \"./dataset/jsquad\"\n",
    "%mkdir -p $dataset_dir\n",
    "!curl -L -s -o $dataset_dir/valid.json https://github.com/yahoojapan/JGLUE/raw/main/datasets/jsquad-v1.3/valid-v1.3.json \n",
    "!curl -L -s -o $dataset_dir/train.json https://github.com/yahoojapan/JGLUE/raw/main/datasets/jsquad-v1.3/train-v1.3.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d63f9c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.44 s, sys: 126 ms, total: 8.56 s\n",
      "Wall time: 8.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def squad_json_to_dataframe(input_file_path, record_path=[\"data\", \"paragraphs\", \"qas\", \"answers\"]):\n",
    "    file = json.loads(open(input_file_path).read())\n",
    "    m = pd.json_normalize(file, record_path[:-1])\n",
    "    r = pd.json_normalize(file, record_path[:-2])\n",
    "\n",
    "    idx = np.repeat(r[\"context\"].values, r.qas.str.len())\n",
    "    m[\"context\"] = idx\n",
    "    m[\"answers\"] = m[\"answers\"]\n",
    "    m[\"answers\"] = m[\"answers\"].apply(lambda x: np.unique(pd.json_normalize(x)[\"text\"].to_list()))\n",
    "    return m[[\"id\", \"question\", \"context\", \"answers\"]]\n",
    "\n",
    "valid_filename = f\"{dataset_dir}/valid.json\"\n",
    "valid_df = squad_json_to_dataframe(valid_filename)\n",
    "\n",
    "train_filename = f\"{dataset_dir}/train.json\"\n",
    "train_df = squad_json_to_dataframe(train_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5d8b19",
   "metadata": {},
   "source": [
    "### サンプルデータの確認\n",
    "サンプルデータは日本語の FAQ データセットです。<br>質問文フィールドの question、回答の answers、説明文の context フィールド、問題 ID である id フィールドから構成されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36ea780c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a10336p0q0</td>\n",
       "      <td>日本で梅雨がないのは北海道とどこか。</td>\n",
       "      <td>梅雨 [SEP] 梅雨（つゆ、ばいう）は、北海道と小笠原諸島を除く日本、朝鮮半島南部、中国の...</td>\n",
       "      <td>[小笠原諸島, 小笠原諸島を除く日本]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a10336p0q1</td>\n",
       "      <td>梅雨とは何季の一種か?</td>\n",
       "      <td>梅雨 [SEP] 梅雨（つゆ、ばいう）は、北海道と小笠原諸島を除く日本、朝鮮半島南部、中国の...</td>\n",
       "      <td>[雨季]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a10336p0q2</td>\n",
       "      <td>梅雨は、世界的にどのあたりで見られる気象ですか？</td>\n",
       "      <td>梅雨 [SEP] 梅雨（つゆ、ばいう）は、北海道と小笠原諸島を除く日本、朝鮮半島南部、中国の...</td>\n",
       "      <td>[東アジア, 東アジアの広範囲]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10336p0q3</td>\n",
       "      <td>梅雨がみられるのはどの期間？</td>\n",
       "      <td>梅雨 [SEP] 梅雨（つゆ、ばいう）は、北海道と小笠原諸島を除く日本、朝鮮半島南部、中国の...</td>\n",
       "      <td>[5月から7月, 5月から7月にかけて]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a10336p1q0</td>\n",
       "      <td>入梅は何の目安の時期か？</td>\n",
       "      <td>梅雨 [SEP] 梅雨の時期が始まることを梅雨入りや入梅（にゅうばい）といい、社会通念上・気...</td>\n",
       "      <td>[春の終わりであるとともに夏の始まり（初夏）, 田植えの時期, 田植えの時期の目安]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>a95156p5q3</td>\n",
       "      <td>国際銀行間通信協会ならびに国際決済機関の何と何も企業体である</td>\n",
       "      <td>多国籍企業 [SEP] 国際銀行間通信協会ならびに国際決済機関のクリアストリームとユーロクリ...</td>\n",
       "      <td>[クリアストリームとユーロクリア]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>a95156p6q0</td>\n",
       "      <td>ゼネコンはどの国特有の形態か</td>\n",
       "      <td>多国籍企業 [SEP] ゼネコンは日本特有の形態。セメントメジャーにラファージュホルシムやイ...</td>\n",
       "      <td>[日本]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>a95156p6q1</td>\n",
       "      <td>多国籍企業においてゼネコンはどこの国特有の形態であるか？</td>\n",
       "      <td>多国籍企業 [SEP] ゼネコンは日本特有の形態。セメントメジャーにラファージュホルシムやイ...</td>\n",
       "      <td>[日本]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>a95156p6q2</td>\n",
       "      <td>多国籍企業を一つ挙げよ</td>\n",
       "      <td>多国籍企業 [SEP] ゼネコンは日本特有の形態。セメントメジャーにラファージュホルシムやイ...</td>\n",
       "      <td>[イタルチェメンティ, ラファージュホルシム]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>a95156p6q3</td>\n",
       "      <td>ゼネコンはどの国の特有の形態か？</td>\n",
       "      <td>多国籍企業 [SEP] ゼネコンは日本特有の形態。セメントメジャーにラファージュホルシムやイ...</td>\n",
       "      <td>[日本]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4442 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                        question  \\\n",
       "0     a10336p0q0              日本で梅雨がないのは北海道とどこか。   \n",
       "1     a10336p0q1                     梅雨とは何季の一種か?   \n",
       "2     a10336p0q2        梅雨は、世界的にどのあたりで見られる気象ですか？   \n",
       "3     a10336p0q3                  梅雨がみられるのはどの期間？   \n",
       "4     a10336p1q0                    入梅は何の目安の時期か？   \n",
       "...          ...                             ...   \n",
       "4437  a95156p5q3  国際銀行間通信協会ならびに国際決済機関の何と何も企業体である   \n",
       "4438  a95156p6q0                  ゼネコンはどの国特有の形態か   \n",
       "4439  a95156p6q1    多国籍企業においてゼネコンはどこの国特有の形態であるか？   \n",
       "4440  a95156p6q2                     多国籍企業を一つ挙げよ   \n",
       "4441  a95156p6q3                ゼネコンはどの国の特有の形態か？   \n",
       "\n",
       "                                                context  \\\n",
       "0     梅雨 [SEP] 梅雨（つゆ、ばいう）は、北海道と小笠原諸島を除く日本、朝鮮半島南部、中国の...   \n",
       "1     梅雨 [SEP] 梅雨（つゆ、ばいう）は、北海道と小笠原諸島を除く日本、朝鮮半島南部、中国の...   \n",
       "2     梅雨 [SEP] 梅雨（つゆ、ばいう）は、北海道と小笠原諸島を除く日本、朝鮮半島南部、中国の...   \n",
       "3     梅雨 [SEP] 梅雨（つゆ、ばいう）は、北海道と小笠原諸島を除く日本、朝鮮半島南部、中国の...   \n",
       "4     梅雨 [SEP] 梅雨の時期が始まることを梅雨入りや入梅（にゅうばい）といい、社会通念上・気...   \n",
       "...                                                 ...   \n",
       "4437  多国籍企業 [SEP] 国際銀行間通信協会ならびに国際決済機関のクリアストリームとユーロクリ...   \n",
       "4438  多国籍企業 [SEP] ゼネコンは日本特有の形態。セメントメジャーにラファージュホルシムやイ...   \n",
       "4439  多国籍企業 [SEP] ゼネコンは日本特有の形態。セメントメジャーにラファージュホルシムやイ...   \n",
       "4440  多国籍企業 [SEP] ゼネコンは日本特有の形態。セメントメジャーにラファージュホルシムやイ...   \n",
       "4441  多国籍企業 [SEP] ゼネコンは日本特有の形態。セメントメジャーにラファージュホルシムやイ...   \n",
       "\n",
       "                                         answers  \n",
       "0                            [小笠原諸島, 小笠原諸島を除く日本]  \n",
       "1                                           [雨季]  \n",
       "2                               [東アジア, 東アジアの広範囲]  \n",
       "3                           [5月から7月, 5月から7月にかけて]  \n",
       "4     [春の終わりであるとともに夏の始まり（初夏）, 田植えの時期, 田植えの時期の目安]  \n",
       "...                                          ...  \n",
       "4437                           [クリアストリームとユーロクリア]  \n",
       "4438                                        [日本]  \n",
       "4439                                        [日本]  \n",
       "4440                     [イタルチェメンティ, ラファージュホルシム]  \n",
       "4441                                        [日本]  \n",
       "\n",
       "[4442 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d186ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1000888p0q0</td>\n",
       "      <td>新たに語（単語）を造ることや、既存の語を組み合わせて新たな意味の語を造ること</td>\n",
       "      <td>造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...</td>\n",
       "      <td>[造語]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1000888p0q1</td>\n",
       "      <td>新たに造られた語のことを新語または何という？</td>\n",
       "      <td>造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...</td>\n",
       "      <td>[新造語]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1000888p0q2</td>\n",
       "      <td>たに語（単語）を造ることや、既存の語を組み合わせて新たな意味の語を造ること、また、そうして造...</td>\n",
       "      <td>造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...</td>\n",
       "      <td>[造語]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1000888p0q3</td>\n",
       "      <td>新たに語を造ることや、既存の語を組み合わせて新たな意味の語を造ることを何という？</td>\n",
       "      <td>造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...</td>\n",
       "      <td>[造語]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1000888p0q4</td>\n",
       "      <td>既存の語を組み合わせたりして新しく単語を造ることを何と言う？</td>\n",
       "      <td>造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...</td>\n",
       "      <td>[造語]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62692</th>\n",
       "      <td>a99943p9q0</td>\n",
       "      <td>ストラングラーズは、どんな車で各地を回っていたか？</td>\n",
       "      <td>パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...</td>\n",
       "      <td>[アイスクリーム販売用のバン]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62693</th>\n",
       "      <td>a99943p9q1</td>\n",
       "      <td>ザ・ジャムが解散したのはいつか？</td>\n",
       "      <td>パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...</td>\n",
       "      <td>[1982年]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62694</th>\n",
       "      <td>a99943p9q2</td>\n",
       "      <td>ストラングラーズは、イギリス国内を何で移動してライヴを行った？</td>\n",
       "      <td>パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...</td>\n",
       "      <td>[アイスクリーム販売用のバン]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62695</th>\n",
       "      <td>a99943p9q3</td>\n",
       "      <td>ザ・ジャムが解散したのは何年か。</td>\n",
       "      <td>パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...</td>\n",
       "      <td>[1982年]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62696</th>\n",
       "      <td>a99943p9q4</td>\n",
       "      <td>アイスクリーム販売用のバンで移動しながらライブを行ったバンドは何か。</td>\n",
       "      <td>パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...</td>\n",
       "      <td>[ストラングラーズ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62697 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                           question  \\\n",
       "0      a1000888p0q0             新たに語（単語）を造ることや、既存の語を組み合わせて新たな意味の語を造ること   \n",
       "1      a1000888p0q1                             新たに造られた語のことを新語または何という？   \n",
       "2      a1000888p0q2  たに語（単語）を造ることや、既存の語を組み合わせて新たな意味の語を造ること、また、そうして造...   \n",
       "3      a1000888p0q3           新たに語を造ることや、既存の語を組み合わせて新たな意味の語を造ることを何という？   \n",
       "4      a1000888p0q4                     既存の語を組み合わせたりして新しく単語を造ることを何と言う？   \n",
       "...             ...                                                ...   \n",
       "62692    a99943p9q0                          ストラングラーズは、どんな車で各地を回っていたか？   \n",
       "62693    a99943p9q1                                   ザ・ジャムが解散したのはいつか？   \n",
       "62694    a99943p9q2                    ストラングラーズは、イギリス国内を何で移動してライヴを行った？   \n",
       "62695    a99943p9q3                                   ザ・ジャムが解散したのは何年か。   \n",
       "62696    a99943p9q4                 アイスクリーム販売用のバンで移動しながらライブを行ったバンドは何か。   \n",
       "\n",
       "                                                 context          answers  \n",
       "0      造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...             [造語]  \n",
       "1      造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...            [新造語]  \n",
       "2      造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...             [造語]  \n",
       "3      造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...             [造語]  \n",
       "4      造語 [SEP] 造語（ぞうご）は、新たに語（単語）を造ることや、既存の語を組み合わせて新た...             [造語]  \n",
       "...                                                  ...              ...  \n",
       "62692  パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...  [アイスクリーム販売用のバン]  \n",
       "62693  パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...          [1982年]  \n",
       "62694  パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...  [アイスクリーム販売用のバン]  \n",
       "62695  パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...          [1982年]  \n",
       "62696  パンク・ロック [SEP] 他に、ザ・ジャムがネオ・モッズ・ムーブメントを巻き起こし、UKチ...       [ストラングラーズ]  \n",
       "\n",
       "[62697 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6486981",
   "metadata": {},
   "source": [
    "### インデックス作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a6b3aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# delete index\n",
      "NotFoundError(404, 'index_not_found_exception', 'no such index [jsquad-kuromoji]')\n",
      "# create index\n",
      "{\n",
      "  \"acknowledged\": true,\n",
      "  \"shards_acknowledged\": true,\n",
      "  \"index\": \"jsquad-kuromoji\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"jsquad-kuromoji\"\n",
    "\n",
    "payload = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question\": {\"type\": \"text\", \"analyzer\": \"custom_kuromoji_analyzer\"},\n",
    "            \"context\": {\"type\": \"text\", \"analyzer\": \"custom_kuromoji_analyzer\"},\n",
    "            \"answers\": {\"type\": \"text\", \"analyzer\": \"custom_kuromoji_analyzer\"},\n",
    "        }\n",
    "    },\n",
    "    \"settings\": {\n",
    "        \"index.number_of_shards\": 1,\n",
    "        \"index.number_of_replicas\": 0,\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"custom_kuromoji_analyzer\": {\n",
    "                    \"char_filter\": [\"icu_normalizer\"],\n",
    "                    \"filter\": [\n",
    "                        \"custom_kuromoji_part_of_speech\",\n",
    "                    ],\n",
    "                    \"tokenizer\": \"kuromoji_tokenizer\",\n",
    "                    \"type\": \"custom\",\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"custom_kuromoji_part_of_speech\": {\n",
    "                    \"type\": \"kuromoji_part_of_speech\",\n",
    "                    \"stoptags\": [\"感動詞,フィラー\",\"接頭辞\",\"代名詞\",\"副詞\",\"助詞\",\"助動詞\",\"動詞,一般,*,*,*,終止形-一般\",\"名詞,普通名詞,副詞可能\"]\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 既に同名のインデックスが存在する場合、いったん削除を行う\n",
    "    print(\"# delete index\")\n",
    "    response = opensearch_client.indices.delete(index=index_name)\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# インデックスの作成を行う\n",
    "print(\"# create index\")\n",
    "response = opensearch_client.indices.create(index=index_name, body=payload)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4358c",
   "metadata": {},
   "source": [
    "### ドキュメントのロード\n",
    "ドキュメントのロードを行います。<br>ドキュメントのロードは \"OpenSearch の基本概念・基本操作の理解\" でも解説した通り bulk API を使用することで効率よく進められますが、データ処理フレームワークを利用することでより簡単にデータを取り込むことも可能です。本ワークショップでは、[AWS SDK for Pandas][aws-sdk-pandas] を使用したデータ取り込みを行います。\n",
    "\n",
    "[aws-sdk-pandas]: https://github.com/aws/aws-sdk-pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8537d56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.08 s, sys: 46.9 ms, total: 6.13 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_name = \"jsquad-kuromoji\"\n",
    "\n",
    "response = wr.opensearch.index_df(\n",
    "    client=opensearch_client,\n",
    "    df=pd.concat([train_df, valid_df]),\n",
    "    use_threads=True,\n",
    "    id_keys=[\"id\"],\n",
    "    index=index_name,\n",
    "    bulk_size=1000,\n",
    "    refresh=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda7609",
   "metadata": {},
   "source": [
    "response[\"success\"] の値が DataFrame の件数と一致しているかを確認します。<br>True が表示される場合は全件登録に成功していると判断できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "781d1f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"success\"] == pd.concat([train_df, valid_df]).id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295a842",
   "metadata": {},
   "source": [
    "### インタラクティブな検索\n",
    "以降は時間の許す限り、自由に検索クエリを実行してみましょう\n",
    "\n",
    "- query テキストボックスの内容を書き換えることで、検索クエリを変更することが可能です\n",
    "- question、context、answers のチェックボックスを ON/OFF で切り替えることで、フィールド単位で検索可否を調整可能です。\n",
    "- 具体的にどの個所にヒットしたかは、highlight.<field-name> のカラムから確認可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb66ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24e7e76f25549b0b4d26d3d8b55560f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='jsquad-kuromoji', description='index_name'), Text(value='シュミレーション 言語', descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.search(index_name, query, question, context, answers)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(index_name, query, question, context, answers):\n",
    "    fields = []\n",
    "    if question:\n",
    "        fields.append(\"question\")\n",
    "    if context:\n",
    "        fields.append(\"context\")\n",
    "    if answers:\n",
    "        fields.append(\"answers\")\n",
    "    payload = {\n",
    "      \"query\": {\n",
    "        \"multi_match\": {\n",
    "          \"query\": query,\n",
    "          \"fields\": fields,\n",
    "          \"operator\": \"and\"\n",
    "        }\n",
    "      },\n",
    "      \"highlight\": {\n",
    "        \"fields\": {\n",
    "          \"*\" : {}\n",
    "        }\n",
    "      },\n",
    "      \"_source\": False,\n",
    "      \"fields\": fields\n",
    "    }\n",
    "    response = opensearch_client.search(\n",
    "        index=index_name,\n",
    "        body=payload\n",
    "    )\n",
    "    return pd.json_normalize(response[\"hits\"][\"hits\"])\n",
    "\n",
    "index_name = \"jsquad-kuromoji\"\n",
    "query = \"シュミレーション 言語\"\n",
    "\n",
    "# テキストボックス\n",
    "interact(search, index_name=index_name, query=query, question=True, context=True, answers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355d1bb",
   "metadata": {},
   "source": [
    "# Kuromoji ユーザー辞書のカスタマイズによる日本語検索の精度改善\n",
    "> この章は、`kutomoji-user-dictionary.ipynb` を元に作成しています。\n",
    "\n",
    "## 概要\n",
    "形態素解析を使用して文章のトークン化を行う場合、辞書が単語認識のベースとなります。したがって、トークン分割の結果がユーザーから見て直感的かどうかは、辞書に依存します。\n",
    "\n",
    "日本語検索プラグインである Kuromoji では、デフォルトで備えている標準辞書に加えて、ユーザー辞書を追加することでトークン分割を適正化することができます。\n",
    "\n",
    "本ラボでは、Kuromoji の標準辞書のカバー範囲と、ユーザー辞書によるトークン分割の改善を実際に行っていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f50b7b",
   "metadata": {},
   "source": [
    "## Kuromoji 標準辞書\n",
    "\n",
    "Kuromoji 標準辞書に登録されている単語は [mecab-ipadic-2.7.0-20070801.tar.gz](http://atilika.com/releases/mecab-ipadic/mecab-ipadic-2.7.0-20070801.tar.gz) 内のファイルから確認することができます。以下はファイルのリストです。\n",
    "\n",
    "| ファイル名                 | 分類                    | 例                                   |\n",
    "| -------------------------- | ----------------------- | ------------------------------------ |\n",
    "| Adj.csv.utf8.txt           | 形容詞                  | 軽い、何気無い、優しい               |\n",
    "| Adnominal.csv.utf8.txt     | 連体詞                  | 確固たる、いわゆる、おかしな         |\n",
    "| Adverb.csv.utf8.txt        | 副詞                    | ぜったいに、多少、なにしろ           |\n",
    "| Auxil.csv.utf8.txt         | 助動詞                  | です、ます、らしく、ある             |\n",
    "| Conjunction.csv.utf8.txt   | 接続詞                  | なので、でも、なお、なら             |\n",
    "| Filler.csv.utf8.txt        | フィラーワード          | あー、えー、うん、まあ               |\n",
    "| Interjection.csv.utf8.txt  | 感動詞(感嘆詞)          | わあ、へー、おはよう                 |\n",
    "| Noun.adjv.csv.utf8.txt     | 名詞(形容動詞語幹)      | きらびやか、温厚、人一倍             |\n",
    "| Noun.adverbal.csv.utf8.txt | 名詞(副詞可能)          | すべて、全員、近頃                   |\n",
    "| Noun.csv.utf8.txt          | 名詞(一般)              | 氏名、コスト、足ぶみ、わたぼうし     |\n",
    "| Noun.demonst.csv.utf8.txt  | 名詞(代名詞)            | 私、君、あれ、これ、それ             |\n",
    "| Noun.nai.csv.utf8.txt      | 名詞(\"ない\" 形容詞語幹) | 申しわけ、しょうが、他愛             |\n",
    "| Noun.name.csv.utf8.txt     | 名詞(固有名詞/人名)     | ノーベル、蘇我蝦夷、長崎、頼朝       |\n",
    "| Noun.number.csv.utf8.txt   | 名詞(数)                | 百、１(全角)、ゼロ、ひと             |\n",
    "| Noun.org.csv.utf8.txt      | 名詞(固有名詞/組織)     | 国会図書館、最高裁判所、造幣局       |\n",
    "| Noun.others.csv.utf8.txt   | 名詞(非自立)            | かぎり、はず、矢先、つもり           |\n",
    "| Noun.place.csv.utf8.txt    | 名詞(固有名詞/地域)     | 関東、東京、目黒                     |\n",
    "| Noun.proper.csv.utf8.txt   | 名詞(固有名詞/一般)     | アマゾン川、幕張メッセ、金毘羅山     |\n",
    "| Noun.verbal.csv.utf8.txt   | 名詞(サ辺接続)          | 改善、感謝、リスクヘッジ、こざっぱり |\n",
    "| Others.csv.utf8.txt        | その他                  | よ、ァ                               |\n",
    "| Postp-col.csv.utf8.txt     | 助詞(格助詞)            | にあたります、を通じて               |\n",
    "| Postp.csv.utf8.txt         | 助詞(特殊)              | て、に、を、は、けども、ながら       |\n",
    "| Prefix.csv.utf8.txt        | 接頭詞                  | 真、大、小、今                       |\n",
    "| Suffix.csv.utf8.txt        | 名詞(接尾/助数詞)       | 人、係、メートル                     |\n",
    "| Symbol.csv.utf8.txt        | 記号                    | ￥、Σ、●、〒                       |\n",
    "| Verb.csv.utf8.txt          | 動詞                    | 探し出す、学ぶ、ぬかるむ             | \n",
    "\n",
    "辞書のエントリファイルの書式は以下のようになっています。\n",
    "\n",
    "`表層形,左文脈ID,右文脈ID,コスト,品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用型,活用形,原形,読み,発音`\n",
    "\n",
    "形容詞や動詞は、活用形ごとに辞書内にエントリが存在し、共通の原形が割り当てられています。活用形ごとに原形を伴って辞書に情報が登録されていることで、活用形の違いによる検索ヒット率の低下を、後段で解説する正規化処理で防ぐことができます。以下は一部ファイルの抜粋です。\n",
    "\n",
    "### Adj.csv.utf8.txt\n",
    "```csv\n",
    "あたたかい,19,19,6948,形容詞,自立,*,*,形容詞・アウオ段,基本形,あたたかい,アタタカイ,アタタカイ\n",
    "あたたかし,23,23,6953,形容詞,自立,*,*,形容詞・アウオ段,文語基本形,あたたかい,アタタカシ,アタタカシ\n",
    "あたたかから,27,27,6953,形容詞,自立,*,*,形容詞・アウオ段,未然ヌ接続,あたたかい,アタタカカラ,アタタカカラ\n",
    "あたたかかろ,25,25,6953,形容詞,自立,*,*,形容詞・アウオ段,未然ウ接続,あたたかい,アタタカカロ,アタタカカロ\n",
    "あたたかかっ,33,33,6952,形容詞,自立,*,*,形容詞・アウオ段,連用タ接続,あたたかい,アタタカカッ,アタタカカッ\n",
    "あたたかく,35,35,6952,形容詞,自立,*,*,形容詞・アウオ段,連用テ接続,あたたかい,アタタカク,アタタカク\n",
    "```\n",
    "\n",
    "### Verb.csv.utf8.txt\n",
    "```csv\n",
    "すみわたる,772,772,9279,動詞,自立,*,*,五段・ラ行,基本形,すみわたる,スミワタル,スミワタル\n",
    "すみわたら,780,780,9279,動詞,自立,*,*,五段・ラ行,未然形,すみわたる,スミワタラ,スミワタラ\n",
    "すみわたん,782,782,9279,動詞,自立,*,*,五段・ラ行,未然特殊,すみわたる,スミワタン,スミワタン\n",
    "すみわたろ,778,778,9279,動詞,自立,*,*,五段・ラ行,未然ウ接続,すみわたる,スミワタロ,スミワタロ\n",
    "すみわたり,788,788,9279,動詞,自立,*,*,五段・ラ行,連用形,すみわたる,スミワタリ,スミワタリ\n",
    "すみわたっ,786,786,9279,動詞,自立,*,*,五段・ラ行,連用タ接続,すみわたる,スミワタッ,スミワタッ\n",
    "```\n",
    "\n",
    "### Noun.verbal.csv.utf8.txt\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b>名詞は活用形を持たないため、原形のみが登録されています。</b>\n",
    "</div>\n",
    "\n",
    "```csv\n",
    "確言,1283,1283,4467,名詞,サ変接続,*,*,*,*,確言,カクゲン,カクゲン\n",
    "行脚,1283,1283,4466,名詞,サ変接続,*,*,*,*,行脚,アンギャ,アンギャ\n",
    "微笑,1283,1283,4087,名詞,サ変接続,*,*,*,*,微笑,ビショウ,ビショー\n",
    "ミート,1283,1283,4426,名詞,サ変接続,*,*,*,*,ミート,ミート,ミート\n",
    "含有,1283,1283,4467,名詞,サ変接続,*,*,*,*,含有,ガンユウ,ガンユー\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fe2d8",
   "metadata": {},
   "source": [
    "## ユーザー辞書\n",
    "エンジンに組み込まれているデフォルトの辞書は全ての固有名詞をカバーしないため、ユーザー辞書に語句を登録することでトークンの抽出が意図したとおりに行われるようになります。\n",
    "\n",
    "### デフォルト辞書が機能しない例\n",
    "\n",
    "標準の Kuromoji Tokenizer では、**[紅まどんな(べにまどんな)](https://ja.wikipedia.org/wiki/%E6%84%9B%E5%AA%9B%E6%9E%9C%E8%A9%A6%E7%AC%AC28%E5%8F%B7)** というキーワードは **紅/ま/どんな** と分割されます。\n",
    "\n",
    "以下は _analyze API の実行例です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a54000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>紅</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ま</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>どんな</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  start_offset  end_offset  type  position\n",
       "0     紅             0           1  word         0\n",
       "1     ま             1           2  word         1\n",
       "2   どんな             2           5  word         2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": [\"紅まどんな\"],\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\",\n",
    "    \"discard_compound_token\": True \n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833cb66",
   "metadata": {},
   "source": [
    "分割された各トークンの読みガナを確認すると、**アカ/マ/ドンナ** となっていることが確認できました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae69050c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>アカ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>マ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ドンナ</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  start_offset  end_offset  type  position\n",
       "0    アカ             0           1  word         0\n",
       "1     マ             1           2  word         1\n",
       "2   ドンナ             2           5  word         2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"紅まどんな\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\",\n",
    "    \"discard_compound_token\": True \n",
    "  },\n",
    "  \"filter\": [\n",
    "    {\n",
    "      \"type\": \"kuromoji_readingform\",\n",
    "      \"use_romaji\": False\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24196f26",
   "metadata": {},
   "source": [
    "### ユーザー辞書の書式\n",
    "\n",
    "Kuromoji はユーザー辞書として以下のフォーマットをサポートしています。\n",
    "\n",
    "`<文字列>,<トークン 1> ... <トークン n>,<読みガナ 1> ... <読みガナ n>,<品詞タグ>`\n",
    "\n",
    "1 つ目のエントリ**<文字列>**では処理対象の文字列を、2 つめのエントリ **<トークン 1> ... <トークン n>** では、入力された文字列の分割単位を、3 つめのエントリ **<読みガナ 1> ... <読みガナ n>** には、トークンの読みガナを、最後のエントリには品詞名を表すタグを記載します。品詞タグには`カスタム名詞`を用いるのが一般的です。\n",
    "\n",
    "**紅まどんな** を **紅まどんな** のまま分割せずにトークン化したい場合は、以下のように記載します。\n",
    "\n",
    "`紅まどんな,紅まどんな,ベニマドンナ,カスタム名詞`\n",
    "\n",
    "このエントリを user_dictionary_rules に追加して、改めて _analyze API を実行し、\"紅まどんな\" が単体のトークンとして抽出されたことを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70525ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>紅まどんな</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  start_offset  end_offset  type  position\n",
       "0  紅まどんな             0           5  word         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"紅まどんな\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\",\n",
    "    \"discard_compound_token\": True,\n",
    "    \"user_dictionary_rules\": [\"紅まどんな,紅まどんな,ベニマドンナ,カスタム名詞\"]\n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990090bd",
   "metadata": {},
   "source": [
    "kuromoji_readingform フィルタを追加して、トークンの読みガナも正しく処理されていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56eb4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ベニマドンナ</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  start_offset  end_offset  type  position\n",
       "0  ベニマドンナ             0           5  word         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": \"紅まどんな\",\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\",\n",
    "    \"discard_compound_token\": True,\n",
    "    \"user_dictionary_rules\": [\"紅まどんな,紅まどんな,ベニマドンナ,カスタム名詞\"]\n",
    "  },\n",
    "  \"filter\": [\n",
    "    {\n",
    "      \"type\": \"kuromoji_readingform\",\n",
    "      \"use_romaji\": False\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff1866",
   "metadata": {},
   "source": [
    "ユーザー辞書を活用することで、以下のようなトークン分割の調整を行うこともできます。\n",
    "\n",
    "- **東京ゲートブリッジ** のように、デフォルトの挙動だと **東京/ゲート/ブリッジ** と 3 つに分割されてしまうトークンを **東京/ゲートブリッジ** と分割位置を調整する\n",
    "- **アイストールラテ** のように単体のトークンとして認識されるものを アイス/トール/ラテ と分割する\n",
    "\n",
    "以下はユーザー辞書追加前のトークン分割結果です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "525ae851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>東京</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ゲート</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ブリッジ</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>word</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>アイストールラテ</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>word</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token  start_offset  end_offset  type  position\n",
       "0        東京             0           2  word         0\n",
       "1       ゲート             2           5  word         1\n",
       "2      ブリッジ             5           9  word         2\n",
       "3  アイストールラテ            10          18  word       103"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": [\"東京ゲートブリッジ\", \"アイストールラテ\"],\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\",\n",
    "    \"discard_compound_token\": True,\n",
    "    \"user_dictionary_rules\": [\"紅まどんな,紅まどんな,ベニマドンナ,カスタム名詞\"]\n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82a306",
   "metadata": {},
   "source": [
    "以下はユーザー辞書定義追加後のトークン分割結果です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fceb07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>東京</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ゲートブリッジ</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>アイス</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>word</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>トール</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>word</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ラテ</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>word</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  start_offset  end_offset  type  position\n",
       "0       東京             0           2  word         0\n",
       "1  ゲートブリッジ             2           9  word         1\n",
       "2      アイス            10          13  word       102\n",
       "3      トール            13          16  word       103\n",
       "4       ラテ            16          18  word       104"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": [\"東京ゲートブリッジ\", \"アイストールラテ\"],\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\",\n",
    "    \"discard_compound_token\": True,\n",
    "    \"user_dictionary_rules\": [\n",
    "      \"紅まどんな,紅まどんな,ベニマドンナ,カスタム名詞\",\n",
    "      \"東京ゲートブリッジ,東京 ゲートブリッジ,トウキョウ ゲートブリッジ,カスタム名詞\",\n",
    "      \"アイストールラテ,アイス トール ラテ,アイス トール ラテ,カスタム名詞\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da75f891",
   "metadata": {},
   "source": [
    "## ユーザー辞書の適用\n",
    "実際のインデックスにユーザー辞書をセットし、辞書の有無による検索精度を比較していきます。Amazon OpenSearch Service では、Kuromoji において以下 2 通りのユーザー辞書セット方法を提供しています。\n",
    "\n",
    "- user_dictionary_rules オプションに直接ユーザー辞書エントリを定義\n",
    "- Amazon OpenSearch Service 独自の、カスタムパッケージ機能の利用\n",
    "\n",
    "本ラボでは user_dictionary_rules オプションを使用してユーザー辞書をインデックスにセットしていきます。\n",
    "\n",
    "### user_dictionary_rules オプションによるユーザー辞書の適用\n",
    "前述の Analyzer API で使用した user_dictionary_rules オプションは、インデックスに対して適用することが可能です。\n",
    "インデックスに対して直接エントリをセットできるため、動作確認を素早く行うことが可能です。\n",
    "\n",
    "インデックスの定義内にエントリを含む性質上、大量のエントリを管理する場合はカスタムパッケージを使用した方がよいでしょう。\n",
    "\n",
    "以降、user_dictionary_rules オプションを使用したユーザー辞書の適用方法を解説していきます。\n",
    "\n",
    "#### インデックスの作成\n",
    "item フィールドおよび、サブフィールドの item.text、item.text_with_userdict フィールドを持つインデックスを定義します。\n",
    "\n",
    "item フィールドは keyword フィールドであるため、完全一致検索で用います。一方で item.text フィールドは Kuromoji のデフォルト辞書のみを使用してトークン分割を行います。item.text_with_userdict フィールドにはユーザー辞書を追加しています。\n",
    "\n",
    "OpenSearch は、子フィールドを定義することで、親フィールドに投入した値を元に子フィールドごとに個別のインデックスを生成し、検索に使用することができます。単一フィールドへのデータ投入で複数のインデックスを作成できるため、クライアント -　OpenSearch 間のペイロードサイズを削減することができるなど、いくつかの面でメリットがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d50431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# delete index\n",
      "NotFoundError(404, 'index_not_found_exception', 'no such index [kuromoji-sample-with-user-dictionary-rules-v1]')\n",
      "# create index\n",
      "{\n",
      "  \"acknowledged\": true,\n",
      "  \"shards_acknowledged\": true,\n",
      "  \"index\": \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "\n",
    "user_dictionary_rules = [\n",
    "    \"紅まどんな,紅まどんな,ベニマドンナ,カスタム名詞\",\n",
    "    \"東京ゲートブリッジ,東京 ゲートブリッジ,トウキョウ ゲートブリッジ,カスタム名詞\",\n",
    "    \"アイストールラテ,アイス トール ラテ,アイス トール ラテ,カスタム名詞\"\n",
    "]\n",
    "\n",
    "payload = {\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"id\": {\"type\": \"keyword\"},\n",
    "      \"item\": {\n",
    "        \"type\": \"keyword\",\n",
    "        \"fields\": {\n",
    "          \"text\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"custom_kuromoji_analyzer\",\n",
    "          },\n",
    "          \"text_with_userdict\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"custom_kuromoji_analyzer_with_userdict\",\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"settings\": {\n",
    "    \"index.number_of_shards\": 1,\n",
    "    \"index.number_of_replicas\": 0,\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"custom_kuromoji_analyzer\": {\n",
    "          \"tokenizer\": \"custom_kuromoji_tokenizer\"\n",
    "        },\n",
    "        \"custom_kuromoji_analyzer_with_userdict\": {\n",
    "          \"tokenizer\": \"custom_kuromoji_tokenizer_with_userdict\",\n",
    "        }\n",
    "      },\n",
    "      \"tokenizer\": {\n",
    "        \"custom_kuromoji_tokenizer\": {\n",
    "          \"type\": \"kuromoji_tokenizer\",\n",
    "          \"mode\": \"search\",\n",
    "          \"discard_compound_token\": True\n",
    "        },\n",
    "        \"custom_kuromoji_tokenizer_with_userdict\": {\n",
    "          \"type\": \"kuromoji_tokenizer\",\n",
    "          \"mode\": \"search\",\n",
    "          \"discard_compound_token\": True,\n",
    "          \"user_dictionary_rules\": user_dictionary_rules\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 既に同名のインデックスが存在する場合、いったん削除を行う\n",
    "    print(\"# delete index\")\n",
    "    response = opensearch_client.indices.delete(index=index_name)\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# インデックスの作成を行う\n",
    "print(\"# create index\")\n",
    "response = opensearch_client.indices.create(index=index_name, body=payload)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62dd03",
   "metadata": {},
   "source": [
    "#### テストデータの投入\n",
    "テストデータを投入します。<br>正しいデータと、元の正しいデータを並べ替えた不正なデータを登録し、検索結果の確認に用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e38ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"took\": 148,\n",
      "  \"errors\": false,\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"kuromoji-sample-with-user-dictionary-rules-v1\",\n",
      "        \"_id\": \"1a\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 0,\n",
      "          \"successful\": 0,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 0,\n",
      "        \"_primary_term\": 0,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"kuromoji-sample-with-user-dictionary-rules-v1\",\n",
      "        \"_id\": \"1b\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 0,\n",
      "          \"successful\": 0,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 0,\n",
      "        \"_primary_term\": 0,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"kuromoji-sample-with-user-dictionary-rules-v1\",\n",
      "        \"_id\": \"2a\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 0,\n",
      "          \"successful\": 0,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 0,\n",
      "        \"_primary_term\": 0,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"kuromoji-sample-with-user-dictionary-rules-v1\",\n",
      "        \"_id\": \"2b\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 0,\n",
      "          \"successful\": 0,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 0,\n",
      "        \"_primary_term\": 0,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"kuromoji-sample-with-user-dictionary-rules-v1\",\n",
      "        \"_id\": \"3\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 0,\n",
      "          \"successful\": 0,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 0,\n",
      "        \"_primary_term\": 0,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "\n",
    "payload = f\"\"\"\n",
    "{{\"index\": {{\"_index\": \"{index_name}\", \"_id\": \"1a\"}}}}\n",
    "{{\"item\": \"紅まどんな\"}}\n",
    "{{\"index\": {{\"_index\": \"{index_name}\", \"_id\": \"1b\"}}}}\n",
    "{{\"item\": \"どんな紅ま\"}}\n",
    "{{\"index\": {{\"_index\": \"{index_name}\", \"_id\": \"2a\"}}}}\n",
    "{{\"item\": \"東京ゲートブリッジ\"}}\n",
    "{{\"index\": {{\"_index\": \"{index_name}\", \"_id\": \"2b\"}}}}\n",
    "{{\"item\": \"東京ブリッジゲート\"}}\n",
    "{{\"index\": {{\"_index\": \"{index_name}\", \"_id\": \"3\"}}}}\n",
    "{{\"item\": \"アイストールラテ\"}}\n",
    "\"\"\"\n",
    "\n",
    "response = opensearch_client.bulk(payload, refresh=False)\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83cd8b3",
   "metadata": {},
   "source": [
    "#### 検索の実行\n",
    "まず、`紅まどんな` で、item.text フィールドに対して検索を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d86d9424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text</th>\n",
       "      <th>highlight.item.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>1b</td>\n",
       "      <td>0.863046</td>\n",
       "      <td>[どんな紅ま]</td>\n",
       "      <td>[&lt;em&gt;どんな&lt;/em&gt;&lt;em&gt;紅&lt;/em&gt;&lt;em&gt;ま&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>1a</td>\n",
       "      <td>0.863046</td>\n",
       "      <td>[紅まどんな]</td>\n",
       "      <td>[&lt;em&gt;紅&lt;/em&gt;&lt;em&gt;ま&lt;/em&gt;&lt;em&gt;どんな&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id    _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1  1b  0.863046   \n",
       "1  kuromoji-sample-with-user-dictionary-rules-v1  1a  0.863046   \n",
       "\n",
       "  fields.item.text                 highlight.item.text  \n",
       "0          [どんな紅ま]  [<em>どんな</em><em>紅</em><em>ま</em>]  \n",
       "1          [紅まどんな]  [<em>紅</em><em>ま</em><em>どんな</em>]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"紅まどんな\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374af15a",
   "metadata": {},
   "source": [
    "上記の結果より、クエリテキストが **紅/ま/どんな** にトークン分割されてからマッチング処理が実行されているため、不要なデータもヒットしていることが確認できました。<br>\n",
    "では、ユーザー辞書によってトークン分割が適正化されている **item.text_with_userdict** フィールドに対して同様のクエリを発行します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7538558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text_with_userdict</th>\n",
       "      <th>highlight.item.text_with_userdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>1a</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>[紅まどんな]</td>\n",
       "      <td>[&lt;em&gt;紅まどんな&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id    _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1  1a  0.287682   \n",
       "\n",
       "  fields.item.text_with_userdict highlight.item.text_with_userdict  \n",
       "0                        [紅まどんな]                  [<em>紅まどんな</em>]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"紅まどんな\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text_with_userdict\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text_with_userdict\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69be3a6",
   "metadata": {},
   "source": [
    "正しく **紅まどんな** だけがヒットしました。また、ハイライトを見ると **紅まどんな** 全体が一つのトークンとして処理されていることが分かります。<br>\n",
    "同様に、**東京ゲートブリッジ** で item.text フィールドの検索を行うと、**東京ブリッジゲート** もヒットしてしまいました。これは **東京/ゲート/ブリッジ** と 3 つのトークンに分割されてしまっていることが理由です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df30a256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text</th>\n",
       "      <th>highlight.item.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>2b</td>\n",
       "      <td>0.863046</td>\n",
       "      <td>[東京ブリッジゲート]</td>\n",
       "      <td>[&lt;em&gt;東京&lt;/em&gt;&lt;em&gt;ブリッジ&lt;/em&gt;&lt;em&gt;ゲート&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>2a</td>\n",
       "      <td>0.863046</td>\n",
       "      <td>[東京ゲートブリッジ]</td>\n",
       "      <td>[&lt;em&gt;東京&lt;/em&gt;&lt;em&gt;ゲート&lt;/em&gt;&lt;em&gt;ブリッジ&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id    _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1  2b  0.863046   \n",
       "1  kuromoji-sample-with-user-dictionary-rules-v1  2a  0.863046   \n",
       "\n",
       "  fields.item.text                     highlight.item.text  \n",
       "0      [東京ブリッジゲート]  [<em>東京</em><em>ブリッジ</em><em>ゲート</em>]  \n",
       "1      [東京ゲートブリッジ]  [<em>東京</em><em>ゲート</em><em>ブリッジ</em>]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"東京ゲートブリッジ\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23e3fb",
   "metadata": {},
   "source": [
    "対策としては match_phrase の利用が考えられますが、この場合、クエリに **東京ゲートブリッジ** 以外も含まれているとそちらも順序判定の対象となってしまいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c35652a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text</th>\n",
       "      <th>highlight.item.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>2a</td>\n",
       "      <td>0.863046</td>\n",
       "      <td>[東京ゲートブリッジ]</td>\n",
       "      <td>[&lt;em&gt;東京&lt;/em&gt;&lt;em&gt;ゲート&lt;/em&gt;&lt;em&gt;ブリッジ&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id    _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1  2a  0.863046   \n",
       "\n",
       "  fields.item.text                     highlight.item.text  \n",
       "0      [東京ゲートブリッジ]  [<em>東京</em><em>ゲート</em><em>ブリッジ</em>]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"東京ゲートブリッジ\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc22fd1",
   "metadata": {},
   "source": [
    "ユーザー辞書によってトークン分割が適正化されている **item.text_with_userdict** フィールドに対して同様のクエリを発行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "147ad6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text_with_userdict</th>\n",
       "      <th>highlight.item.text_with_userdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>2a</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>[東京ゲートブリッジ]</td>\n",
       "      <td>[&lt;em&gt;東京&lt;/em&gt;&lt;em&gt;ゲートブリッジ&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id    _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1  2a  0.575364   \n",
       "\n",
       "  fields.item.text_with_userdict highlight.item.text_with_userdict  \n",
       "0                    [東京ゲートブリッジ]     [<em>東京</em><em>ゲートブリッジ</em>]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"東京ゲートブリッジ\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text_with_userdict\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text_with_userdict\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9b051",
   "metadata": {},
   "source": [
    "**ゲートブリッジ** がトークン分割されないことで、正しいドキュメントだけを取得することができました。\n",
    "最後にアイストールラテを検索していきます。アイストールラテを検索する際に、ラテのアイスでサイズはトール、と考えて **ラテ アイス トール** で検索を行います。\n",
    "\n",
    "検索対象のフィールドは、ユーザー辞書が適用されていない **item.text** フィールドです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd12a593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"ラテ アイス トール\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a887a7",
   "metadata": {},
   "source": [
    "残念ながらヒットしません。これは **アイストールラテ** で単一トークンと認識されているためです。実際にアイストールラテで検索した結果は以下の通りです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b15eef3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text</th>\n",
       "      <th>highlight.item.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>[アイストールラテ]</td>\n",
       "      <td>[&lt;em&gt;アイストールラテ&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id    _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1   3  0.287682   \n",
       "\n",
       "  fields.item.text  highlight.item.text  \n",
       "0       [アイストールラテ]  [<em>アイストールラテ</em>]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"アイストールラテ\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181f2cd",
   "metadata": {},
   "source": [
    "ユーザー辞書によってトークン分割が適正化されている **item.text_with_userdict** フィールドに対して同様のクエリを発行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54077008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text_with_userdict</th>\n",
       "      <th>highlight.item.text_with_userdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.863046</td>\n",
       "      <td>[アイストールラテ]</td>\n",
       "      <td>[&lt;em&gt;アイス&lt;/em&gt;&lt;em&gt;トール&lt;/em&gt;&lt;em&gt;ラテ&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id    _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1   3  0.863046   \n",
       "\n",
       "  fields.item.text_with_userdict      highlight.item.text_with_userdict  \n",
       "0                     [アイストールラテ]  [<em>アイス</em><em>トール</em><em>ラテ</em>]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"ラテ アイス トール\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text_with_userdict\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\",\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text_with_userdict\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab11132",
   "metadata": {},
   "source": [
    "無事にヒットしました。アイストールラテが **アイス/トール/ラテ** の 3 つのトークンに分割されることで、順序が異なるキーワードによる検索でもヒットするようになりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e304b9",
   "metadata": {},
   "source": [
    "## ユーザー辞書の更新\n",
    "ユーザー辞書は、検索要件やトレンドの変化に合わせて継続的なメンテナンスが必要です。Kuromoji のユーザー辞書更新はオンラインでインデックスに反映されないため、一般的には何らかの静止点を設けて更新作業を行う必要があります。 \n",
    "\n",
    "辞書の更新を行う場合、一般的には以下 3 通りの作業方法から選択します。\n",
    "\n",
    "### 既存のインデックスに格納されたデータを利用して、登録されたデータの更新を実施\n",
    "既存のインデックスに格納されたソースデータを利用して、インデックス内のデータの再登録を行う方式です。[Update by query][update-by-query] API を実行するだけで再登録ができるため最も楽に更新を実行できますが、以下の点に注意する必要があります。\n",
    "\n",
    "- 辞書定義の更新処理のために、一時的にインデックスを [Close index][close-index] API で閉じる必要あり。この間はデータ更新も検索もできない\n",
    "- データの再登録処理中は、辞書更新前/更新後のデータが混在する。この間の検索結果は一貫性が保てない\n",
    "- 辞書の更新による問題が発生した場合は、更新前のエントリに戻して再度 update_by_query を実行する必要がある\n",
    "- 大量のドキュメントが登録されているインデックスに対する update_by_query は時間がかかる\n",
    "\n",
    "作業は以下の流れで行います\n",
    "\n",
    "1. (カスタムパッケージを利用している場合は)カスタムパッケージを更新\n",
    "1. インデックスを [Close index][close-index] API で閉じる\n",
    "1. (user_dictionary_rules) を使用している場合は、ここでユーザー辞書のエントリを更新\n",
    "1. インデックスを [Open index][open-index] API で開ける\n",
    "1. [Update by query][update-by-query] API によるドキュメントの再登録を実行\n",
    "\n",
    "\n",
    "### 更新後の辞書が適用された新規インデックスを作成し、データを再登録\n",
    "新しい辞書定義を含む空の新規インデックスを作成し、既存インデックスからデータをコピー、テスト後にトラフィックを新規のインデックスに切り替える方式です。\n",
    "\n",
    "[Update by query][update-by-query] API 方式はインデックスの close を伴うため、検索処理も一時的にストップします。一方でこちらの方式は、データ更新こそ停止断面を確保する必要がありますが、検索処理を止めずに辞書の切り替えが可能です。このため、多くの本番運用で採用されています。\n",
    "\n",
    "インデックス内のドキュメント更新処理を停止できることが理想です。ドキュメント更新処理を停止できない場合は、両系更新を検討するとよいです。\n",
    "\n",
    "作業は以下の流れで行います。\n",
    "\n",
    "1. ユーザー辞書のエントリを更新\n",
    "1. 新しい辞書エントリを元に、新規にインデックスを作成\n",
    "1. インデックスに対する更新処理を停止\n",
    "1. 新規のインデックスにデータを再登録\n",
    "1. [Alias][alias] API を使用し、現行インデックスから新規インデックスにエイリアスを切り替え\n",
    "1. インデックスに対する更新処理を再開。以降は新規インデックスに対してデータ更新を行う\n",
    "\n",
    "再登録は、初期登録時と同様に、マスターデータを外部から取得して Bulk API 等で書き込む方法と、[Reindex][reindex-data] API を使用する方法があります。Reindex API は、OpenSearch のインデックスに登録されたドキュメントを取得し、別のインデックスに書き込む機能です。\n",
    "\n",
    "### インデックスの両系更新\n",
    "更新処理に伴うデータ登録の停止時間が取れない場合は、両系更新を検討することになります。\n",
    "ひとつ前のデータ再登録方式と似ていますが、既存インデックス用と新規インデックス用で、別々のデータ更新パイプライン(あるいはバッチ処理)を用意する必要がある点が異なります。\n",
    "\n",
    "1. ユーザー辞書のエントリを更新\n",
    "1. 新しい辞書エントリを元に、新規にインデックスを作成\n",
    "1. 既存のデータ更新パイプラインと同じ構成のパイプラインを、新規インデックス向けにも構築し、既存インデックスと新規インデックスそれぞれで、データが最新状態を保てる状態を確保する\n",
    "1. _alias API を使用し、現行インデックスから新規インデックスにエイリアスを切り替え\n",
    "1. インデックスに対する更新処理を再開。以降は新規インデックスに対してデータ更新を行う\n",
    "\n",
    "本ラボでは、update_by_query、および reindex + alias による辞書更新方法を解説します。\n",
    "\n",
    "[update-by-query]: https://opensearch.org/docs/latest/api-reference/document-apis/update-by-query/\n",
    "[open-index]: https://opensearch.org/docs/latest/api-reference/index-apis/open-index/\n",
    "[close-index]: https://opensearch.org/docs/latest/api-reference/index-apis/close-index/\n",
    "[alias]: https://opensearch.org/docs/latest/api-reference/index-apis/alias/\n",
    "[reindex-data]: https://opensearch.org/docs/latest/im-plugin/reindex-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38bf54",
   "metadata": {},
   "source": [
    "### user_dictionary_rules オプションを使用したインデックスに対する辞書更新\n",
    "今度は、ホットミルクティーとホットミルクラテの区切り位置を改善することで、さらに検索精度を上げていきましょう。\n",
    "\n",
    "#### デフォルトのトークン分割結果の確認\n",
    "デフォルトの Kuromoji analyzer の挙動を見てみましょう。ホットミルクティーは **ホッ/トミルクティー** と分割されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "919756ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ホッ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>トミルクティー</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  start_offset  end_offset  type  position\n",
       "0       ホッ             0           2  word         0\n",
       "1  トミルクティー             2           9  word         1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": [\"ホットミルクティー\"],\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\",\n",
    "    \"discard_compound_token\": True \n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ae9c3",
   "metadata": {},
   "source": [
    "同様にホットミルクラテも **ホッ/トミルクラテ** に分割されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76c5bb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ホッ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>トミルクラテ</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  start_offset  end_offset  type  position\n",
       "0      ホッ             0           2  word         0\n",
       "1  トミルクラテ             2           8  word         1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\n",
    "  \"text\": [\"ホットミルクラテ\"],\n",
    "  \"tokenizer\": {\n",
    "    \"type\": \"kuromoji_tokenizer\",\n",
    "    \"mode\": \"search\",\n",
    "    \"discard_compound_token\": True\n",
    "  }\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882070cb",
   "metadata": {},
   "source": [
    "実際にホットミルクティーを登録して検索を行ってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7c35714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"took\": 112,\n",
      "  \"errors\": false,\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"kuromoji-sample-with-user-dictionary-rules-v1\",\n",
      "        \"_id\": \"4\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 0,\n",
      "          \"successful\": 0,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 0,\n",
      "        \"_primary_term\": 0,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "\n",
    "payload = f\"\"\"\n",
    "{{\"index\": {{\"_index\": \"{index_name}\", \"_id\": \"4\"}}}}\n",
    "{{\"item\": \"ホットミルクティー\"}}\n",
    "\"\"\"\n",
    "\n",
    "response = opensearch_client.bulk(payload, refresh=False)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944e1eba",
   "metadata": {},
   "source": [
    "**ホットミルクティー** では item.text フィールドおよび item.text_with_userdict フィールド双方にヒットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac401484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text</th>\n",
       "      <th>fields.item.text_with_userdict</th>\n",
       "      <th>highlight.item.text</th>\n",
       "      <th>highlight.item.text_with_userdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.509825</td>\n",
       "      <td>[ホットミルクティー]</td>\n",
       "      <td>[ホットミルクティー]</td>\n",
       "      <td>[&lt;em&gt;ホッ&lt;/em&gt;&lt;em&gt;トミルクティー&lt;/em&gt;]</td>\n",
       "      <td>[&lt;em&gt;ホッ&lt;/em&gt;&lt;em&gt;トミルクティー&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id    _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1   4  1.509825   \n",
       "\n",
       "  fields.item.text fields.item.text_with_userdict  \\\n",
       "0      [ホットミルクティー]                    [ホットミルクティー]   \n",
       "\n",
       "             highlight.item.text highlight.item.text_with_userdict  \n",
       "0  [<em>ホッ</em><em>トミルクティー</em>]     [<em>ホッ</em><em>トミルクティー</em>]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"ホットミルクティー\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"multi_match\": {\n",
    "      \"fields\": [\"item.text\", \"item.text_with_userdict\"],\n",
    "      \"query\": query,\n",
    "      \"operator\": \"and\"\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\", \"item.text_with_userdict\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e31a5cd",
   "metadata": {},
   "source": [
    "**ミルクティー ホット** ではいずれのフィールドにもヒットしません。ホットミルクティーに対するユーザ辞書エントリがないので、これは想定通りの結果といえます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91b84c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"ミルクティー ホット\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"multi_match\": {\n",
    "      \"fields\": [\"item.text\", \"item.text_with_userdict\"],\n",
    "      \"query\": query,\n",
    "      \"operator\": \"and\"\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\", \"item.text_with_userdict\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb059a9",
   "metadata": {},
   "source": [
    "ここで、ヒットしない理由を API を使って確かめていきましょう。\n",
    "\n",
    "[Analyze][analyze] API と [Explain][explain] API を実行して、登録時と検索時のトークン分割の様子を比較していきます。\n",
    "\n",
    "まずは、Analyze API を実行して、**ホットミルクティー** を登録する際に、文字列がどのようにトークン分割されているかを確認します。\n",
    "\n",
    "[analyze]: https://opensearch.org/docs/latest/api-reference/analyze-apis/\n",
    "[explain]: https://opensearch.org/docs/latest/api-reference/explain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ea9efd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ホッ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>トミルクティー</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  start_offset  end_offset  type  position\n",
       "0       ホッ             0           2  word         0\n",
       "1  トミルクティー             2           9  word         1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "\n",
    "payload = {\n",
    "  \"text\": \"ホットミルクティー\",\n",
    "  \"analyzer\": \"custom_kuromoji_analyzer_with_userdict\"\n",
    "}\n",
    "response = opensearch_client.indices.analyze(\n",
    "  index=index_name,\n",
    "  body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eeefb7",
   "metadata": {},
   "source": [
    "次に、Explain API を利用することで、クエリテキストがどのように分解されて内部で検索処理が行われているかを確認します。Analyzer API にクエリテキストを渡しても確認することができますが、Explain API ではクエリと対象のドキュメントを指定することで、実際に分割後のトークンごとにマッチするか確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e48f96c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_index\": \"kuromoji-sample-with-user-dictionary-rules-v1\",\n",
      "  \"_id\": \"4\",\n",
      "  \"matched\": true,\n",
      "  \"explanation\": {\n",
      "    \"value\": 1.2199391,\n",
      "    \"description\": \"sum of:\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"value\": 0.60996956,\n",
      "        \"description\": \"weight(item.text:ホッ in 0) [PerFieldSimilarity], result of:\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"value\": 0.60996956,\n",
      "            \"description\": \"score(freq=1.0), computed as boost * idf * tf from:\",\n",
      "            \"details\": [\n",
      "              {\n",
      "                \"value\": 2.2,\n",
      "                \"description\": \"boost\",\n",
      "                \"details\": []\n",
      "              },\n",
      "              {\n",
      "                \"value\": 0.6931472,\n",
      "                \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 1,\n",
      "                    \"description\": \"n, number of documents containing term\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 2,\n",
      "                    \"description\": \"N, total number of documents with field\",\n",
      "                    \"details\": []\n",
      "                  }\n",
      "                ]\n",
      "              },\n",
      "              {\n",
      "                \"value\": 0.40000004,\n",
      "                \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 1.0,\n",
      "                    \"description\": \"freq, occurrences of term within document\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 1.2,\n",
      "                    \"description\": \"k1, term saturation parameter\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 0.75,\n",
      "                    \"description\": \"b, length normalization parameter\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 2.0,\n",
      "                    \"description\": \"dl, length of field\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 1.5,\n",
      "                    \"description\": \"avgdl, average length of field\",\n",
      "                    \"details\": []\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"value\": 0.60996956,\n",
      "        \"description\": \"weight(item.text:トミルクティー in 0) [PerFieldSimilarity], result of:\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"value\": 0.60996956,\n",
      "            \"description\": \"score(freq=1.0), computed as boost * idf * tf from:\",\n",
      "            \"details\": [\n",
      "              {\n",
      "                \"value\": 2.2,\n",
      "                \"description\": \"boost\",\n",
      "                \"details\": []\n",
      "              },\n",
      "              {\n",
      "                \"value\": 0.6931472,\n",
      "                \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 1,\n",
      "                    \"description\": \"n, number of documents containing term\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 2,\n",
      "                    \"description\": \"N, total number of documents with field\",\n",
      "                    \"details\": []\n",
      "                  }\n",
      "                ]\n",
      "              },\n",
      "              {\n",
      "                \"value\": 0.40000004,\n",
      "                \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
      "                \"details\": [\n",
      "                  {\n",
      "                    \"value\": 1.0,\n",
      "                    \"description\": \"freq, occurrences of term within document\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 1.2,\n",
      "                    \"description\": \"k1, term saturation parameter\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 0.75,\n",
      "                    \"description\": \"b, length normalization parameter\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 2.0,\n",
      "                    \"description\": \"dl, length of field\",\n",
      "                    \"details\": []\n",
      "                  },\n",
      "                  {\n",
      "                    \"value\": 1.5,\n",
      "                    \"description\": \"avgdl, average length of field\",\n",
      "                    \"details\": []\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"ホットミルクティー\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "}\n",
    "response = opensearch_client.explain(\n",
    "    index=index_name,\n",
    "    body=payload,\n",
    "    id=4 #ドキュメント\"ホットミルクティー\"の ID\n",
    ")\n",
    "print(json.dumps(response, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e31524a",
   "metadata": {},
   "source": [
    "ドキュメント登録時のトークンと、クエリ時のトークン、いずれも **ホッ/トミルクティー**であるため、検索ヒットしたことが確認できました。\n",
    "\n",
    "では、**ミルクティー ホット** ではどうでしょうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3a1016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_index\": \"kuromoji-sample-with-user-dictionary-rules-v1\",\n",
      "  \"_id\": \"4\",\n",
      "  \"matched\": false,\n",
      "  \"explanation\": {\n",
      "    \"value\": 0.0,\n",
      "    \"description\": \"Failure to meet condition(s) of required/prohibited clause(s)\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"value\": 0.0,\n",
      "        \"description\": \"no match on required clause (item.text:ミルク)\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"value\": 0.0,\n",
      "            \"description\": \"no matching term\",\n",
      "            \"details\": []\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"value\": 0.0,\n",
      "        \"description\": \"no match on required clause (item.text:ティー)\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"value\": 0.0,\n",
      "            \"description\": \"no matching term\",\n",
      "            \"details\": []\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"value\": 0.0,\n",
      "        \"description\": \"no match on required clause (item.text:ホット)\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"value\": 0.0,\n",
      "            \"description\": \"no matching term\",\n",
      "            \"details\": []\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"ミルクティー ホット\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "}\n",
    "response = opensearch_client.explain(\n",
    "    index=index_name,\n",
    "    body=payload,\n",
    "    id=4 #ドキュメント\"ホットミルクティー\"の ID\n",
    ")\n",
    "print(json.dumps(response, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2c9c1",
   "metadata": {},
   "source": [
    "**ミルクティー ホット** で検索を行った場合、クエリは **ミルク/ティー/ホット** にトークン分割されていることが分かります。\n",
    "\n",
    "一方、Analyze API 実行結果より、**ホットミルクティー** というドキュメントは、登録時に **ホッ/トミルクティー** というトークンに分割されていることが確認できています。\n",
    "\n",
    "検索時のトークンと、登録時のトークンにずれがあることが、**ミルクティー ホット** で **ホットミルクティー**が検索できない原因であると確認できました。\n",
    "\n",
    "登録されている時と同じトークン分割結果である **ホッ/トミルクティー** で検索してみましょう。このクエリは一見すると不自然ですが、登録時のトークンと同一であることからヒットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14b5bf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text</th>\n",
       "      <th>highlight.item.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.219939</td>\n",
       "      <td>[ホットミルクティー]</td>\n",
       "      <td>[&lt;em&gt;ホッ&lt;/em&gt;&lt;em&gt;トミルクティー&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id    _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1   4  1.219939   \n",
       "\n",
       "  fields.item.text            highlight.item.text  \n",
       "0      [ホットミルクティー]  [<em>ホッ</em><em>トミルクティー</em>]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"ホッ トミルクティー\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05386223",
   "metadata": {},
   "source": [
    "また、**ホッ** や **トミルクティー** など、単一のトークンで検索してもヒットしてしまいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "484830bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text</th>\n",
       "      <th>highlight.item.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60997</td>\n",
       "      <td>[ホットミルクティー]</td>\n",
       "      <td>[&lt;em&gt;ホッ&lt;/em&gt;トミルクティー]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id   _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1   4  0.60997   \n",
       "\n",
       "  fields.item.text   highlight.item.text  \n",
       "0      [ホットミルクティー]  [<em>ホッ</em>トミルクティー]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"ホッ\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2aeebb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>fields.item.text</th>\n",
       "      <th>highlight.item.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kuromoji-sample-with-user-dictionary-rules-v1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60997</td>\n",
       "      <td>[ホットミルクティー]</td>\n",
       "      <td>[ホッ&lt;em&gt;トミルクティー&lt;/em&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _index _id   _score  \\\n",
       "0  kuromoji-sample-with-user-dictionary-rules-v1   4  0.60997   \n",
       "\n",
       "  fields.item.text   highlight.item.text  \n",
       "0      [ホットミルクティー]  [ホッ<em>トミルクティー</em>]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "query = \"トミルクティー\"\n",
    "\n",
    "payload = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item.text\": {\n",
    "        \"query\": query,\n",
    "        \"operator\": \"and\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"*\" : {}\n",
    "    }\n",
    "  },\n",
    "  \"_source\": False,\n",
    "  \"fields\": [\"item.text\"]\n",
    "}\n",
    "response = opensearch_client.search(\n",
    "    index=index_name,\n",
    "    body=payload\n",
    ")\n",
    "pd.json_normalize(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0dd37",
   "metadata": {},
   "source": [
    "#### ユーザー辞書定義の更新\n",
    "analyze API を使用することで入力時のトークン分割の様子が、explain API を使用することで検索時のトークン分割の様子が分かりました。登録・検索時のトークン分割を一致させることが、検索精度向上の鍵であることも分かりました。\n",
    "\n",
    "ここからは、**ミルクティー ホット** でもヒットするように、**ホットミルクティー** が **ホット/ミルク/ティー** で区切られるようにユーザー辞書を作成していきましょう。\n",
    "\n",
    "既存インデックスの user_dictonary_rules を以下の通り更新します。\n",
    "合わせて **ホットミルクラテ** 用のエントリーも追加しておきます。\n",
    "\n",
    "更新作業の前後で、Close API によるインデックスのクローズ、Open API によるインデックスのオープンを実行しています。\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "本ラボで使用しているインデックスはサイズが小さいため、Close から Open も含む更新にかかる所要時間は 1 秒未満ですが、一般的に Close/Open にかかる時間はインデックスサイズに応じて増加していくため、本番環境で本作業を実施する場合は事前の検証が必要です。\n",
    "</div>\n",
    "\n",
    "> AOSS では、`close()` がサポートされていないので、スキップします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997497",
   "metadata": {},
   "source": [
    "#### Update by query API によるデータの再登録\n",
    "\n",
    "既存のドキュメントを、新しい辞書エントリを元に改めてトークン分割しなおすためには、ドキュメントの再登録が必要となります。\n",
    "\n",
    "外部にマスターデータがある場合は、外部から改めてデータの全登録を行うことがお勧めですが、本セクションでは [Update by query][update-by-query] API を使用します。Update by query API を実行することで、インデックスに登録されたドキュメント自身のデータをもとに、ドキュメントの再登録を行うことができます。\n",
    "\n",
    "Update by query は完了まで長時間要する場合があるため、wait_for_completion オプションに False をセットし、非同期で実行することを推奨します。\n",
    "\n",
    "[update-by-query]: https://opensearch.org/docs/latest/api-reference/document-apis/update-by-query/\n",
    "\n",
    "> AOSS では、`update_by_query()` も使えません。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35475c72",
   "metadata": {},
   "source": [
    "#### Reindex API によるデータの再登録 + Alias API によるアクセス先インデックスの切り替え\n",
    "ここからは、Reindex API と Alias API を組み合わせた辞書更新について解説します。\n",
    "\n",
    "##### エイリアスの登録\n",
    "エイリアスは、インデックスに付与可能な別名です。\n",
    "\n",
    "エイリアスはインデックス間でオンラインでの付け替えが可能であるため、バージョンが複数存在するインデックスに対して、クライアントからは常に同じ名前でアクセスしたい場合に有用です。\n",
    "\n",
    "エイリアスは、Alias API を使用して付与します。以下のサンプルコードでは、インデックス **kuromoji-sample-with-user-dictionary-rules-v1** にエイリアス **kuromoji-sample-with-user-dictionary-rules** をセットしています。\n",
    "\n",
    "> AOSS では、`put_alias()` が使えません。\n",
    "\n",
    "##### Reindex による部分更新\n",
    "Reindex 実行時にクエリパラメーターを追加することで、特定の条件に合致したドキュメントだけをコピーすることができます。クエリで更新対象のドキュメントの絞り込みが可能である場合は、Reindex 実行時間を短縮することが可能です。\n",
    "\n",
    "例えば、更新時刻を示すフィールドを持っているドキュメントであれば、range クエリで特定時刻以前のドキュメントのみ再登録を行うことが可能です。\n",
    "\n",
    "今回は、v1 にドキュメントが追加されたことを想定して、差分コピーを実行していきます。\n",
    "\n",
    "> AOSS では、`reindex()` もできません。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e072d",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "本ラボでは、OpenSearch の日本語検索について学習しました。<br>\n",
    "また、Kuromoji のユーザ辞書カスタマイズによる日本語検索の精度改善について学習しました。\n",
    "\n",
    "本ラボで学習した内容を元に、次のステップとして以下のラボを実行してみましょう。\n",
    "\n",
    "### ベクトル検索など他の検索手法を学びたい方向け\n",
    "- [ベクトル検索の実装 (Amazon Bedrock 編)](4-ai-search.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc5a25",
   "metadata": {},
   "source": [
    "## 後片付け\n",
    "\n",
    "### インデックス削除\n",
    "本ワークショップで使用したインデックスを削除します。インデックスの削除は Delete index API で行います。インデックスを削除するとインデックス内のドキュメントも削除されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4adff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"acknowledged\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"jsquad-kuromoji\"\n",
    "\n",
    "try:\n",
    "    response = opensearch_client.indices.delete(index=index_name)\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9811c5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"acknowledged\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"kuromoji-sample-with-user-dictionary-rules-v1\"\n",
    "\n",
    "try:\n",
    "    response = opensearch_client.indices.delete(index=index_name)\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2367d81",
   "metadata": {},
   "source": [
    "### データセット削除\n",
    "ダウンロードしたデータセットを削除します。./dataset ディレクトリ配下に何もない場合は、./dataset ディレクトリも合わせて削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad9287ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf {dataset_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1e078e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmdir: failed to remove './dataset': Directory not empty\n"
     ]
    }
   ],
   "source": [
    "%rmdir ./dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aoss-bedrock-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
